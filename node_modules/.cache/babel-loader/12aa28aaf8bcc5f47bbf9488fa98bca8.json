{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\n\nexport class FileChunkIterator extends ByteChunkIterator {\n  constructor(file, options = {}) {\n    super();\n    this.file = file;\n    this.options = options;\n    util.assert(file instanceof Uint8Array || (env().get('IS_BROWSER') ? file instanceof File || file instanceof Blob : false), () => 'FileChunkIterator only supports File, Blob and Uint8Array ' + 'right now.');\n    this.offset = options.offset || 0; // default 1MB chunk has tolerable perf on large files\n\n    this.chunkSize = options.chunkSize || 1024 * 1024;\n  }\n\n  summary() {\n    return \"FileChunks \".concat(this.file);\n  }\n\n  async next() {\n    if (this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size)) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const chunk = new Promise((resolve, reject) => {\n      const end = this.offset + this.chunkSize;\n\n      if (this.file instanceof Uint8Array) {\n        // Note if end > this.uint8Array.byteLength, we just get a small last\n        // chunk.\n        resolve(new Uint8Array(this.file.slice(this.offset, end)));\n      } else {\n        // This branch assumes that this.file type is File or Blob, which\n        // means it is in the browser environment.\n        // TODO(soergel): is this a performance issue?\n        const fileReader = new FileReader();\n\n        fileReader.onload = event => {\n          let data = fileReader.result; // Not sure we can trust the return type of\n          // FileReader.readAsArrayBuffer See e.g.\n          // https://github.com/node-file-api/FileReader/issues/2\n\n          if (data instanceof ArrayBuffer) {\n            data = new Uint8Array(data);\n          }\n\n          if (!(data instanceof Uint8Array)) {\n            return reject(new TypeError('FileReader returned unknown type.'));\n          }\n\n          resolve(data);\n        };\n\n        fileReader.onabort = event => {\n          return reject(new Error('Aborted'));\n        };\n\n        fileReader.onerror = event => {\n          return reject(new Error(event.type));\n        }; // TODO(soergel): better handle onabort, onerror\n        // Note if end > this.file.size, we just get a small last chunk.\n\n\n        const slice = this.file.slice(this.offset, end); // We can't use readAsText here (even if we know the file is text)\n        // because the slice boundary may fall within a multi-byte character.\n\n        fileReader.readAsArrayBuffer(slice);\n      }\n\n      this.offset = end;\n    });\n    return {\n      value: await chunk,\n      done: false\n    };\n  }\n\n}","map":null,"metadata":{},"sourceType":"module"}