{"ast":null,"code":"import _slicedToArray from \"/home/victor/COVID-19-Coding-Fest/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(graph, parent) {\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._signature = graph.signature;\n    this._functions = graph.functions; // create sub-graph executors\n\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  get weightIds() {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap() {\n    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n  }\n\n  get weightMap() {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap) {\n    const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  get inputs() {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n\n  get outputs() {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n\n  get inputNodes() {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes() {\n    return this._outputs.map(node => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? \"\".concat(name, \":\").concat(node.defaultOutput) : name;\n    });\n  }\n\n  get functions() {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {});\n  }\n\n  getCompilationKey(inputs, outputs) {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n  }\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n\n\n  compile(inputs, outputs) {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap);\n    const missingInputs = executionInfo.missingInputs,\n          dynamicNode = executionInfo.dynamicNode,\n          syncInputs = executionInfo.syncInputs;\n\n    if (dynamicNode != null) {\n      throw new Error(\"This execution contains the node '\".concat(dynamicNode.name, \"', which has \") + \"the dynamic op '\".concat(dynamicNode.op, \"'. Please use \") + \"model.executeAsync() instead. Alternatively, to avoid the \" + \"dynamic ops, specify the inputs [\".concat(syncInputs, \"]\"));\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\"Cannot compute the outputs [\".concat(outNames, \"] from the provided inputs \") + \"[\".concat(inNames, \"]. Missing the following inputs: [\").concat(missingInputs, \"]\"));\n    }\n\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n  }\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n\n\n  execute(inputs, outputs) {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodes = outputs.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes); // Do nothing if the compiled graph cache contains the input.\n\n    let orderedNodes = this.compiledMap.get(compilationKey);\n\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n\n    const tensorArrayMap = {};\n    const tensorListMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n      const tensorsMap = Object.assign({}, this.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const _parseNodeName = parseNodeName(name),\n              _parseNodeName2 = _slicedToArray(_parseNodeName, 2),\n              nodeName = _parseNodeName2[0],\n              index = _parseNodeName2[1];\n\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount = {};\n\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context);\n\n          if (tensors instanceof Promise) {\n            throw new Error(\"The execution of the op '\".concat(node.op, \"' returned a promise. \") + \"Please use model.executeAsync() instead.\");\n          }\n\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputs, intermediateTensorConsumerCount);\n        }\n      } // dispose the context for the root executor\n\n\n      if (this.parent == null) {\n        context.dispose();\n      }\n\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  getFrozenTensorIds(tensorMap) {\n    const ids = [].concat.apply([], Object.keys(tensorMap).map(key => tensorMap[key]).map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n\n  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n\n\n  async executeAsync(inputs, outputs) {\n    return this._executeAsync(inputs, outputs);\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   * @param isFunctionExecution Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n\n\n  async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap); // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n\n    const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorMap, context)); // dispose all the intermediate tensors\n\n    const outputIds = new Set(results.map(t => t.id));\n    const inputIds = new Set(Object.keys(inputs).map(name => inputs[name].id));\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !outputIds.has(tensor.id) && !inputIds.has(tensor.id) && this.weightIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n    }); // dispose the context for the root executor\n\n    if (this.parent == null) {\n      context.dispose();\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {});\n    return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n\n\n  async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n    const names = Object.keys(inputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodes = outputNames.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n\n    const _getExecutionSubgraph = getExecutionSubgraph(inputs, outputNodes, this.weightMap),\n          usedNodes = _getExecutionSubgraph.usedNodes,\n          missingInputs = _getExecutionSubgraph.missingInputs,\n          dynamicNode = _getExecutionSubgraph.dynamicNode,\n          syncInputs = _getExecutionSubgraph.syncInputs;\n\n    const stack = [...inputNodes, ...this.graph.weights].map(node => {\n      return {\n        node,\n        contexts: context.currentContext\n      };\n    });\n    const tensorsMap = Object.assign({}, this.weightMap);\n    Object.keys(inputs).forEach(name => {\n      const _parseNodeName3 = parseNodeName(name),\n            _parseNodeName4 = _slicedToArray(_parseNodeName3, 2),\n            nodeName = _parseNodeName4[0],\n            index = _parseNodeName4[1];\n\n      const tensors = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added = {};\n\n    while (stack.length > 0) {\n      const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\"This model execution did not contain any nodes with control flow \" + \"or dynamic output shapes. You can use model.execute() instead.\");\n    }\n\n    const missingOutputs = outputNodes.filter(node => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map(node => node.name);\n\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n\n      if (dynamicNode != null) {\n        alternativeMsg = \"Alternatively, to avoid the dynamic ops, use model.execute() \" + \"and specify the inputs [\".concat(syncInputs, \"]\");\n      }\n\n      throw new Error(\"Cannot compute the outputs [\".concat(missingOutputs, \"] from the provided \") + \"inputs [\".concat(names, \"]. Consider providing the following inputs: \") + \"[\".concat(missingInputs, \"]. \").concat(alternativeMsg));\n    }\n\n    return tensorsMap;\n  }\n\n  processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n    const promises = [];\n\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = ''; // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n\n      if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n        var _getNodeNameAndIndex = getNodeNameAndIndex(item.node.name, context);\n\n        var _getNodeNameAndIndex2 = _slicedToArray(_getNodeNameAndIndex, 1);\n\n        nodeName = _getNodeNameAndIndex2[0];\n      } // only process nodes that are not provided as input nodes.\n\n\n      if (inputNodes.indexOf(item.node) === -1) {\n        const tensors = executeOp(item.node, tensorMap, context);\n\n        if (!nodeName) {\n          var _getNodeNameAndIndex3 = getNodeNameAndIndex(item.node.name, context);\n\n          var _getNodeNameAndIndex4 = _slicedToArray(_getNodeNameAndIndex3, 1);\n\n          nodeName = _getNodeNameAndIndex4[0];\n        }\n\n        const currentContext = context.currentContext;\n\n        if (tensors instanceof Promise) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n\n    return promises;\n  }\n\n  processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n    node.children.forEach(childNode => {\n      const _getNodeNameAndIndex5 = getNodeNameAndIndex(childNode.name, context),\n            _getNodeNameAndIndex6 = _slicedToArray(_getNodeNameAndIndex5, 1),\n            nodeName = _getNodeNameAndIndex6[0];\n\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      } // Merge op can be pushed if any of its inputs has value.\n\n\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n      } else // Otherwise all inputs must to have value.\n        if (childNode.inputNames.every(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n    });\n  }\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n\n\n  dispose() {\n    Object.keys(this.weightMap).forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  checkInputShapeAndType(inputs) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n\n      const _parseNodeName5 = parseNodeName(name),\n            _parseNodeName6 = _slicedToArray(_parseNodeName5, 1),\n            nodeName = _parseNodeName6[0];\n\n      const node = this.graph.nodes[nodeName];\n\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value;\n        const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(match, () => \"The shape of dict['\".concat(node.name, \"'] provided in \") + \"model.execute(dict) must be [\".concat(shape, \"], but was \") + \"[\".concat(input.shape, \"]\"));\n      }\n\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(input.dtype === node.attrParams['dtype'].value, () => \"The dtype of dict['\".concat(node.name, \"'] provided in \") + \"model.execute(dict) must be \" + \"\".concat(node.attrParams['dtype'].value, \", but was \").concat(input.dtype));\n      }\n    });\n  }\n\n  mapInputs(inputs) {\n    const result = {};\n\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n\n    return result;\n  }\n\n  checkInputs(inputs) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const _parseNodeName7 = parseNodeName(name),\n            _parseNodeName8 = _slicedToArray(_parseNodeName7, 1),\n            nodeName = _parseNodeName8[0];\n\n      return this.graph.nodes[nodeName] == null;\n    });\n\n    if (notInGraph.length > 0) {\n      throw new Error(\"The dict provided in model.execute(dict) has \" + \"keys: [\".concat(notInGraph, \"] that are not part of graph\"));\n    }\n  }\n\n  mapOutputs(outputs) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null && this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n\n      return name;\n    }, {});\n  }\n\n  checkOutputs(outputs) {\n    outputs.forEach(name => {\n      const _parseNodeName9 = parseNodeName(name),\n            _parseNodeName10 = _slicedToArray(_parseNodeName9, 1),\n            normalizedName = _parseNodeName10[0];\n\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(\"The output '\".concat(name, \"' is not found in the graph\"));\n      }\n    });\n  }\n\n}","map":null,"metadata":{},"sourceType":"module"}