{"ast":null,"code":"import _slicedToArray from \"/home/victor/COVID-19-Coding-Fest/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { dispose } from '../globals';\nimport { assert } from '../util';\nimport { clone } from './clone';\nimport { concat } from './concat';\nimport { div } from './div';\nimport { eye } from './eye';\nimport { greater } from './greater';\nimport { matMul } from './mat_mul';\nimport { mul } from './mul';\nimport { neg } from './neg';\nimport { norm } from './norm';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { slice } from './slice';\nimport { stack } from './stack';\nimport { sub } from './sub';\nimport { tensor2d } from './tensor2d';\nimport { transpose } from './transpose';\nimport { unstack } from './unstack';\nimport { where } from './where';\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n */\n\n/**\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\n\nfunction qr_(x, fullMatrices = false) {\n  assert(x.rank >= 2, () => \"qr() requires input tensor to have a rank >= 2, but got rank \".concat(x.rank));\n\n  if (x.rank === 2) {\n    return qr2d(x, fullMatrices);\n  } else {\n    // Rank > 2.\n    // TODO(cais): Below we split the input into individual 2D tensors,\n    //   perform QR decomposition on them and then stack the results back\n    //   together. We should explore whether this can be parallelized.\n    const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);\n    const x2ds = unstack(reshape(x, [outerDimsProd, x.shape[x.shape.length - 2], x.shape[x.shape.length - 1]]), 0);\n    const q2ds = [];\n    const r2ds = [];\n    x2ds.forEach(x2d => {\n      const _qr2d = qr2d(x2d, fullMatrices),\n            _qr2d2 = _slicedToArray(_qr2d, 2),\n            q2d = _qr2d2[0],\n            r2d = _qr2d2[1];\n\n      q2ds.push(q2d);\n      r2ds.push(r2d);\n    });\n    const q = reshape(stack(q2ds, 0), x.shape);\n    const r = reshape(stack(r2ds, 0), x.shape);\n    return [q, r];\n  }\n}\n\nfunction qr2d(x, fullMatrices = false) {\n  return ENGINE.tidy(() => {\n    assert(x.shape.length === 2, () => \"qr2d() requires a 2D Tensor, but got a \".concat(x.shape.length, \"D Tensor.\"));\n    const m = x.shape[0];\n    const n = x.shape[1];\n    let q = eye(m); // Orthogonal transform so far.\n\n    let r = clone(x); // Transformed matrix so far.\n\n    const one2D = tensor2d([[1]], [1, 1]);\n    let w = clone(one2D);\n    const iters = m >= n ? n : m;\n\n    for (let j = 0; j < iters; ++j) {\n      // This tidy within the for-loop ensures we clean up temporary\n      // tensors as soon as they are no longer needed.\n      const rTemp = r;\n      const wTemp = w;\n      const qTemp = q;\n\n      var _ENGINE$tidy = ENGINE.tidy(() => {\n        // Find H = I - tau * w * w', to put zeros below R(j, j).\n        const rjEnd1 = slice(r, [j, j], [m - j, 1]);\n        const normX = norm(rjEnd1);\n        const rjj = slice(r, [j, j], [1, 1]); // The sign() function returns 0 on 0, which causes division by zero.\n\n        const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));\n        const u1 = sub(rjj, mul(s, normX));\n        const wPre = div(rjEnd1, u1);\n\n        if (wPre.shape[0] === 1) {\n          w = clone(one2D);\n        } else {\n          w = concat([one2D, slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])], 0);\n        }\n\n        const tau = neg(div(matMul(s, u1), normX)); // -- R := HR, Q := QH.\n\n        const rjEndAll = slice(r, [j, 0], [m - j, n]);\n        const tauTimesW = mul(tau, w);\n        const wT = transpose(w);\n\n        if (j === 0) {\n          r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n        } else {\n          const rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);\n        }\n\n        const tawTimesWT = transpose(tauTimesW);\n        const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);\n\n        if (j === 0) {\n          q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n        } else {\n          const qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);\n        }\n\n        return [w, r, q];\n      });\n\n      var _ENGINE$tidy2 = _slicedToArray(_ENGINE$tidy, 3);\n\n      w = _ENGINE$tidy2[0];\n      r = _ENGINE$tidy2[1];\n      q = _ENGINE$tidy2[2];\n      dispose([rTemp, wTemp, qTemp]);\n    }\n\n    if (!fullMatrices && m > n) {\n      q = slice(q, [0, 0], [m, n]);\n      r = slice(r, [0, 0], [n, n]);\n    }\n\n    return [q, r];\n  });\n}\n\nexport const qr = op({\n  qr_\n});","map":null,"metadata":{},"sourceType":"module"}