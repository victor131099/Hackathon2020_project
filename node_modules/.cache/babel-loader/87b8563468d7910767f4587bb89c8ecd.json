{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Convolutional Layers\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport { imageDataFormat } from '../backend/common';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { convOutputLength, deconvLength, normalizeArray } from '../utils/conv_utils';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\n/**\n * Transpose and cast the input before the conv2d.\n * @param x Input image tensor.\n * @param dataFormat\n */\n\nexport function preprocessConv2DInput(x, dataFormat) {\n  // TODO(cais): Cast type to float32 if not.\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n\n    if (dataFormat === 'channelsFirst') {\n      return tfc.transpose(x, [0, 2, 3, 1]); // NCHW -> NHWC.\n    } else {\n      return x;\n    }\n  });\n}\n/**\n * Transpose and cast the input before the conv3d.\n * @param x Input image tensor.\n * @param dataFormat\n */\n\nexport function preprocessConv3DInput(x, dataFormat) {\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n\n    if (dataFormat === 'channelsFirst') {\n      return tfc.transpose(x, [0, 2, 3, 4, 1]); // NCDHW -> NDHWC.\n    } else {\n      return x;\n    }\n  });\n}\n/**\n * 1D-convolution with bias added.\n *\n * Porting Note: This function does not exist in the Python Keras backend.\n *   It is exactly the same as `conv2d`, except the added `bias`.\n *\n * @param x Input tensor, rank-3, of shape `[batchSize, width, inChannels]`.\n * @param kernel Kernel, rank-3, of shape `[filterWidth, inDepth, outDepth]`.\n * @param bias Bias, rank-3, of shape `[outDepth]`.\n * @param strides\n * @param padding Padding mode.\n * @param dataFormat Data format.\n * @param dilationRate\n * @returns The result of the 1D convolution.\n * @throws ValueError, if `x`, `kernel` or `bias` is not of the correct rank.\n */\n\nexport function conv1dWithBias(x, kernel, bias, strides = 1, padding = 'valid', dataFormat, dilationRate = 1) {\n  return tidy(() => {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n\n    checkDataFormat(dataFormat); // Check the ranks of x, kernel and bias.\n\n    if (x.shape.length !== 3) {\n      throw new ValueError(\"The input of a conv1dWithBias operation should be 3, but is \" + \"\".concat(x.shape.length, \" instead.\"));\n    }\n\n    if (kernel.shape.length !== 3) {\n      throw new ValueError(\"The kernel for a conv1dWithBias operation should be 3, but is \" + \"\".concat(kernel.shape.length, \" instead\"));\n    }\n\n    if (bias != null && bias.shape.length !== 1) {\n      throw new ValueError(\"The bias for a conv1dWithBias operation should be 1, but is \" + \"\".concat(kernel.shape.length, \" instead\"));\n    } // TODO(cais): Support CAUSAL padding mode.\n\n\n    if (dataFormat === 'channelsFirst') {\n      x = tfc.transpose(x, [0, 2, 1]); // NCW -> NWC.\n    }\n\n    if (padding === 'causal') {\n      throw new NotImplementedError('The support for CAUSAL padding mode in conv1dWithBias is not ' + 'implemented yet.');\n    }\n\n    let y = tfc.conv1d(x, kernel, strides, padding === 'same' ? 'same' : 'valid', 'NWC', dilationRate);\n\n    if (bias != null) {\n      y = K.biasAdd(y, bias);\n    }\n\n    return y;\n  });\n}\n/**\n * 1D-convolution.\n *\n * @param x Input tensor, rank-3, of shape `[batchSize, width, inChannels]`.\n * @param kernel Kernel, rank-3, of shape `[filterWidth, inDepth, outDepth]`.s\n * @param strides\n * @param padding Padding mode.\n * @param dataFormat Data format.\n * @param dilationRate\n * @returns The result of the 1D convolution.\n * @throws ValueError, if `x`, `kernel` or `bias` is not of the correct rank.\n */\n\nexport function conv1d(x, kernel, strides = 1, padding = 'valid', dataFormat, dilationRate = 1) {\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n    return conv1dWithBias(x, kernel, null, strides, padding, dataFormat, dilationRate);\n  });\n}\n/**\n * 2D Convolution\n * @param x\n * @param kernel kernel of the convolution.\n * @param strides strides array.\n * @param padding padding mode. Default to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param dilationRate dilation rate array.\n * @returns Result of the 2D pooling.\n */\n\nexport function conv2d(x, kernel, strides = [1, 1], padding = 'valid', dataFormat, dilationRate) {\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n    return conv2dWithBiasActivation(x, kernel, null, strides, padding, dataFormat, dilationRate);\n  });\n}\n/**\n * 2D Convolution with an added bias and optional activation.\n * Note: This function does not exist in the Python Keras Backend. This function\n * is exactly the same as `conv2d`, except the added `bias`.\n */\n\nexport function conv2dWithBiasActivation(x, kernel, bias, strides = [1, 1], padding = 'valid', dataFormat, dilationRate, activation = null) {\n  return tidy(() => {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n\n    checkDataFormat(dataFormat);\n\n    if (x.rank !== 3 && x.rank !== 4) {\n      throw new ValueError(\"conv2dWithBiasActivation expects input to be of rank 3 or 4, \" + \"but received \".concat(x.rank, \".\"));\n    }\n\n    if (kernel.rank !== 3 && kernel.rank !== 4) {\n      throw new ValueError(\"conv2dWithBiasActivation expects kernel to be of rank 3 or 4, \" + \"but received \".concat(x.rank, \".\"));\n    }\n\n    let y = preprocessConv2DInput(x, dataFormat);\n\n    if (padding === 'causal') {\n      throw new NotImplementedError('The support for CAUSAL padding mode in conv1dWithBias is not ' + 'implemented yet.');\n    }\n\n    y = tfc.fused.conv2d({\n      x: y,\n      filter: kernel,\n      strides: strides,\n      pad: padding === 'same' ? 'same' : 'valid',\n      dilations: dilationRate,\n      dataFormat: 'NHWC',\n      bias,\n      activation\n    });\n\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 3, 1, 2]);\n    }\n\n    return y;\n  });\n}\n/**\n * 3D Convolution.\n * @param x\n * @param kernel kernel of the convolution.\n * @param strides strides array.\n * @param padding padding mode. Default to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param dilationRate dilation rate array.\n * @returns Result of the 3D convolution.\n */\n\nexport function conv3d(x, kernel, strides = [1, 1, 1], padding = 'valid', dataFormat, dilationRate) {\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n    return conv3dWithBias(x, kernel, null, strides, padding, dataFormat, dilationRate);\n  });\n}\n/**\n * 3D Convolution with an added bias.\n * Note: This function does not exist in the Python Keras Backend. This function\n * is exactly the same as `conv3d`, except the added `bias`.\n */\n\nexport function conv3dWithBias(x, kernel, bias, strides = [1, 1, 1], padding = 'valid', dataFormat, dilationRate) {\n  return tidy(() => {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n\n    checkDataFormat(dataFormat);\n\n    if (x.rank !== 4 && x.rank !== 5) {\n      throw new ValueError(\"conv3dWithBias expects input to be of rank 4 or 5, but received \" + \"\".concat(x.rank, \".\"));\n    }\n\n    if (kernel.rank !== 4 && kernel.rank !== 5) {\n      throw new ValueError(\"conv3dWithBias expects kernel to be of rank 4 or 5, but received \" + \"\".concat(x.rank, \".\"));\n    }\n\n    let y = preprocessConv3DInput(x, dataFormat);\n\n    if (padding === 'causal') {\n      throw new NotImplementedError('The support for CAUSAL padding mode in conv3dWithBias is not ' + 'implemented yet.');\n    }\n\n    y = tfc.conv3d(y, kernel, strides, padding === 'same' ? 'same' : 'valid', 'NDHWC', dilationRate);\n\n    if (bias != null) {\n      y = K.biasAdd(y, bias);\n    }\n\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 4, 1, 2, 3]);\n    }\n\n    return y;\n  });\n}\n/**\n * Abstract convolution layer.\n */\n\nexport class BaseConv extends Layer {\n  constructor(rank, args) {\n    super(args);\n    this.bias = null;\n    this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    BaseConv.verifyArgs(args);\n    this.rank = rank;\n    generic_utils.assertPositiveInteger(this.rank, 'rank');\n\n    if (this.rank !== 1 && this.rank !== 2 && this.rank !== 3) {\n      throw new NotImplementedError(\"Convolution layer for rank other than 1, 2, or 3 (\".concat(this.rank, \") is \") + \"not implemented yet.\");\n    }\n\n    this.kernelSize = normalizeArray(args.kernelSize, rank, 'kernelSize');\n    this.strides = normalizeArray(args.strides == null ? 1 : args.strides, rank, 'strides');\n    this.padding = args.padding == null ? 'valid' : args.padding;\n    checkPaddingMode(this.padding);\n    this.dataFormat = args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n    checkDataFormat(this.dataFormat);\n    this.activation = getActivation(args.activation);\n    this.useBias = args.useBias == null ? true : args.useBias;\n    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.dilationRate = normalizeArray(args.dilationRate == null ? 1 : args.dilationRate, rank, 'dilationRate');\n\n    if (this.rank === 1 && Array.isArray(this.dilationRate) && this.dilationRate.length !== 1) {\n      throw new ValueError(\"dilationRate must be a number or an array of a single number \" + \"for 1D convolution, but received \" + \"\".concat(JSON.stringify(this.dilationRate)));\n    } else if (this.rank === 2) {\n      if (typeof this.dilationRate === 'number') {\n        this.dilationRate = [this.dilationRate, this.dilationRate];\n      } else if (this.dilationRate.length !== 2) {\n        throw new ValueError(\"dilationRate must be a number or array of two numbers for 2D \" + \"convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n      }\n    } else if (this.rank === 3) {\n      if (typeof this.dilationRate === 'number') {\n        this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];\n      } else if (this.dilationRate.length !== 3) {\n        throw new ValueError(\"dilationRate must be a number or array of three numbers for 3D \" + \"convolution, but received \".concat(JSON.stringify(this.dilationRate)));\n      }\n    }\n  }\n\n  static verifyArgs(args) {\n    // Check config.kernelSize type and shape.\n    generic_utils.assert('kernelSize' in args, \"required key 'kernelSize' not in config\");\n\n    if (typeof args.kernelSize !== 'number' && !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 3)) {\n      throw new ValueError(\"BaseConv expects config.kernelSize to be number or number[] with \" + \"length 1, 2, or 3, but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n    }\n  }\n\n  getConfig() {\n    const config = {\n      kernelSize: this.kernelSize,\n      strides: this.strides,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/**\n * Abstract nD convolution layer.  Ancestor of convolution layers which reduce\n * across channels, i.e., Conv1D and Conv2D, but not DepthwiseConv2D.\n */\n\nexport class Conv extends BaseConv {\n  constructor(rank, args) {\n    super(rank, args);\n    this.kernel = null;\n    Conv.verifyArgs(args);\n    this.filters = args.filters;\n    generic_utils.assertPositiveInteger(this.filters, 'filters');\n    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n  }\n\n  build(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(\"The channel dimension of the input should be defined. \" + \"Found \".concat(inputShape[channelAxis]));\n    }\n\n    const inputDim = inputShape[channelAxis];\n    const kernelShape = this.kernelSize.concat([inputDim, this.filters]);\n    this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n    if (this.useBias) {\n      this.bias = this.addWeight('bias', [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.inputSpec = [{\n      ndim: this.rank + 2,\n      axes: {\n        [channelAxis]: inputDim\n      }\n    }];\n    this.built = true;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      let outputs;\n      const biasValue = this.bias == null ? null : this.bias.read();\n      const fusedActivationName = generic_utils.mapActivationToFusedKernel(this.activation.getClassName());\n\n      if (fusedActivationName != null && this.rank === 2) {\n        outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate, fusedActivationName);\n      } else {\n        if (this.rank === 1) {\n          outputs = conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);\n        } else if (this.rank === 2) {\n          // TODO(cais): Move up to constructor.\n          outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);\n        } else if (this.rank === 3) {\n          outputs = conv3dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);\n        } else {\n          throw new NotImplementedError('convolutions greater than 3D are not implemented yet.');\n        }\n\n        if (this.activation != null) {\n          outputs = this.activation.apply(outputs);\n        }\n      }\n\n      return outputs;\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const newSpace = [];\n    const space = this.dataFormat === 'channelsLast' ? inputShape.slice(1, inputShape.length - 1) : inputShape.slice(2);\n\n    for (let i = 0; i < space.length; ++i) {\n      const newDim = convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === 'number' ? this.dilationRate : this.dilationRate[i]);\n      newSpace.push(newDim);\n    }\n\n    let outputShape = [inputShape[0]];\n\n    if (this.dataFormat === 'channelsLast') {\n      outputShape = outputShape.concat(newSpace);\n      outputShape.push(this.filters);\n    } else {\n      outputShape.push(this.filters);\n      outputShape = outputShape.concat(newSpace);\n    }\n\n    return outputShape;\n  }\n\n  getConfig() {\n    const config = {\n      filters: this.filters,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  static verifyArgs(args) {\n    // Check config.filters type, shape, and value.\n    if (!('filters' in args) || typeof args.filters !== 'number' || args.filters < 1) {\n      throw new ValueError(\"Convolution layer expected config.filters to be a 'number' > 0 \" + \"but got \".concat(JSON.stringify(args.filters)));\n    }\n  }\n\n}\nexport class Conv2D extends Conv {\n  constructor(args) {\n    super(2, args);\n    Conv2D.verifyArgs(args);\n  }\n\n  getConfig() {\n    const config = super.getConfig();\n    delete config['rank'];\n    return config;\n  }\n\n  static verifyArgs(args) {\n    // config.kernelSize must be a number or array of numbers.\n    if (typeof args.kernelSize !== 'number' && !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 2)) {\n      throw new ValueError(\"Conv2D expects config.kernelSize to be number or number[] with \" + \"length 1 or 2, but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n    }\n  }\n\n}\n/** @nocollapse */\n\nConv2D.className = 'Conv2D';\nserialization.registerClass(Conv2D);\nexport class Conv3D extends Conv {\n  constructor(args) {\n    super(3, args);\n    Conv3D.verifyArgs(args);\n  }\n\n  getConfig() {\n    const config = super.getConfig();\n    delete config['rank'];\n    return config;\n  }\n\n  static verifyArgs(args) {\n    // config.kernelSize must be a number or array of numbers.\n    if (typeof args.kernelSize !== 'number') {\n      if (!(Array.isArray(args.kernelSize) && (args.kernelSize.length === 1 || args.kernelSize.length === 3))) {\n        throw new ValueError(\"Conv3D expects config.kernelSize to be number or\" + \" [number, number, number], but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n      }\n    }\n  }\n\n}\n/** @nocollapse */\n\nConv3D.className = 'Conv3D';\nserialization.registerClass(Conv3D);\nexport class Conv2DTranspose extends Conv2D {\n  constructor(args) {\n    super(args);\n    this.inputSpec = [new InputSpec({\n      ndim: 4\n    })];\n\n    if (this.padding !== 'same' && this.padding !== 'valid') {\n      throw new ValueError(\"Conv2DTranspose currently supports only padding modes 'same' \" + \"and 'valid', but received padding mode \".concat(this.padding));\n    }\n  }\n\n  build(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    if (inputShape.length !== 4) {\n      throw new ValueError('Input should have rank 4; Received input shape: ' + JSON.stringify(inputShape));\n    }\n\n    const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError('The channel dimension of the inputs should be defined. ' + 'Found `None`.');\n    }\n\n    const inputDim = inputShape[channelAxis];\n    const kernelShape = this.kernelSize.concat([this.filters, inputDim]);\n    this.kernel = this.addWeight('kernel', kernelShape, 'float32', this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n    if (this.useBias) {\n      this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n    } // Set input spec.\n\n\n    this.inputSpec = [new InputSpec({\n      ndim: 4,\n      axes: {\n        [channelAxis]: inputDim\n      }\n    })];\n    this.built = true;\n  }\n\n  call(inputs, kwargs) {\n    return tfc.tidy(() => {\n      let input = getExactlyOneTensor(inputs);\n\n      if (input.shape.length !== 4) {\n        throw new ValueError(\"Conv2DTranspose.call() expects input tensor to be rank-4, but \" + \"received a tensor of rank-\".concat(input.shape.length));\n      }\n\n      const inputShape = input.shape;\n      const batchSize = inputShape[0];\n      let hAxis;\n      let wAxis;\n\n      if (this.dataFormat === 'channelsFirst') {\n        hAxis = 2;\n        wAxis = 3;\n      } else {\n        hAxis = 1;\n        wAxis = 2;\n      }\n\n      const height = inputShape[hAxis];\n      const width = inputShape[wAxis];\n      const kernelH = this.kernelSize[0];\n      const kernelW = this.kernelSize[1];\n      const strideH = this.strides[0];\n      const strideW = this.strides[1]; // Infer the dynamic output shape.\n\n      const outHeight = deconvLength(height, strideH, kernelH, this.padding);\n      const outWidth = deconvLength(width, strideW, kernelW, this.padding); // Porting Note: We don't branch based on `this.dataFormat` here,\n      // because\n      //   the tjfs-core function `conv2dTranspose` called below always\n      //   assumes channelsLast.\n\n      const outputShape = [batchSize, outHeight, outWidth, this.filters];\n\n      if (this.dataFormat !== 'channelsLast') {\n        input = tfc.transpose(input, [0, 2, 3, 1]);\n      }\n\n      let outputs = tfc.conv2dTranspose(input, this.kernel.read(), outputShape, this.strides, this.padding);\n\n      if (this.dataFormat !== 'channelsLast') {\n        outputs = tfc.transpose(outputs, [0, 3, 1, 2]);\n      }\n\n      if (this.bias != null) {\n        outputs = K.biasAdd(outputs, this.bias.read(), this.dataFormat);\n      }\n\n      if (this.activation != null) {\n        outputs = this.activation.apply(outputs);\n      }\n\n      return outputs;\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    let channelAxis;\n    let heightAxis;\n    let widthAxis;\n\n    if (this.dataFormat === 'channelsFirst') {\n      channelAxis = 1;\n      heightAxis = 2;\n      widthAxis = 3;\n    } else {\n      channelAxis = 3;\n      heightAxis = 1;\n      widthAxis = 2;\n    }\n\n    const kernelH = this.kernelSize[0];\n    const kernelW = this.kernelSize[1];\n    const strideH = this.strides[0];\n    const strideW = this.strides[1];\n    outputShape[channelAxis] = this.filters;\n    outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);\n    outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);\n    return outputShape;\n  }\n\n  getConfig() {\n    const config = super.getConfig();\n    delete config['dilationRate'];\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nConv2DTranspose.className = 'Conv2DTranspose';\nserialization.registerClass(Conv2DTranspose);\nexport class SeparableConv extends Conv {\n  constructor(rank, config) {\n    super(rank, config);\n    this.DEFAULT_DEPTHWISE_INITIALIZER = 'glorotUniform';\n    this.DEFAULT_POINTWISE_INITIALIZER = 'glorotUniform';\n    this.depthwiseKernel = null;\n    this.pointwiseKernel = null;\n\n    if (config.filters == null) {\n      throw new ValueError('The `filters` configuration field is required by SeparableConv, ' + 'but is unspecified.');\n    }\n\n    if (config.kernelInitializer != null || config.kernelRegularizer != null || config.kernelConstraint != null) {\n      throw new ValueError('Fields kernelInitializer, kernelRegularizer and kernelConstraint ' + 'are invalid for SeparableConv2D. Use depthwiseInitializer, ' + 'depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, ' + 'pointwiseRegularizer and pointwiseConstraint instead.');\n    }\n\n    if (config.padding != null && config.padding !== 'same' && config.padding !== 'valid') {\n      throw new ValueError(\"SeparableConv\".concat(this.rank, \"D supports only padding modes: \") + \"'same' and 'valid', but received \".concat(JSON.stringify(config.padding)));\n    }\n\n    this.depthMultiplier = config.depthMultiplier == null ? 1 : config.depthMultiplier;\n    this.depthwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER);\n    this.depthwiseRegularizer = getRegularizer(config.depthwiseRegularizer);\n    this.depthwiseConstraint = getConstraint(config.depthwiseConstraint);\n    this.pointwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER);\n    this.pointwiseRegularizer = getRegularizer(config.pointwiseRegularizer);\n    this.pointwiseConstraint = getConstraint(config.pointwiseConstraint);\n  }\n\n  build(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    if (inputShape.length < this.rank + 2) {\n      throw new ValueError(\"Inputs to SeparableConv\".concat(this.rank, \"D should have rank \") + \"\".concat(this.rank + 2, \", but received input shape: \") + \"\".concat(JSON.stringify(inputShape)));\n    }\n\n    const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n      throw new ValueError(\"The channel dimension of the inputs should be defined, \" + \"but found \".concat(JSON.stringify(inputShape[channelAxis])));\n    }\n\n    const inputDim = inputShape[channelAxis];\n    const depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);\n    const pointwiseKernelShape = [];\n\n    for (let i = 0; i < this.rank; ++i) {\n      pointwiseKernelShape.push(1);\n    }\n\n    pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);\n    const trainable = true;\n    this.depthwiseKernel = this.addWeight('depthwise_kernel', depthwiseKernelShape, 'float32', this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);\n    this.pointwiseKernel = this.addWeight('pointwise_kernel', pointwiseKernelShape, 'float32', this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);\n\n    if (this.useBias) {\n      this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);\n    } else {\n      this.bias = null;\n    }\n\n    this.inputSpec = [new InputSpec({\n      ndim: this.rank + 2,\n      axes: {\n        [channelAxis]: inputDim\n      }\n    })];\n    this.built = true;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      let output;\n\n      if (this.rank === 1) {\n        throw new NotImplementedError('1D separable convolution is not implemented yet.');\n      } else if (this.rank === 2) {\n        if (this.dataFormat === 'channelsFirst') {\n          inputs = tfc.transpose(inputs, [0, 2, 3, 1]); // NCHW -> NHWC.\n        }\n\n        output = tfc.separableConv2d(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, 'NHWC');\n      }\n\n      if (this.useBias) {\n        output = K.biasAdd(output, this.bias.read(), this.dataFormat);\n      }\n\n      if (this.activation != null) {\n        output = this.activation.apply(output);\n      }\n\n      if (this.dataFormat === 'channelsFirst') {\n        output = tfc.transpose(output, [0, 3, 1, 2]); // NHWC -> NCHW.\n      }\n\n      return output;\n    });\n  }\n\n  getConfig() {\n    const config = super.getConfig();\n    delete config['rank'];\n    delete config['kernelInitializer'];\n    delete config['kernelRegularizer'];\n    delete config['kernelConstraint'];\n    config['depthwiseInitializer'] = serializeInitializer(this.depthwiseInitializer);\n    config['pointwiseInitializer'] = serializeInitializer(this.pointwiseInitializer);\n    config['depthwiseRegularizer'] = serializeRegularizer(this.depthwiseRegularizer);\n    config['pointwiseRegularizer'] = serializeRegularizer(this.pointwiseRegularizer);\n    config['depthwiseConstraint'] = serializeConstraint(this.depthwiseConstraint);\n    config['pointwiseConstraint'] = serializeConstraint(this.pointwiseConstraint);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nSeparableConv.className = 'SeparableConv';\nexport class SeparableConv2D extends SeparableConv {\n  constructor(args) {\n    super(2, args);\n  }\n\n}\n/** @nocollapse */\n\nSeparableConv2D.className = 'SeparableConv2D';\nserialization.registerClass(SeparableConv2D);\nexport class Conv1D extends Conv {\n  constructor(args) {\n    super(1, args);\n    Conv1D.verifyArgs(args);\n    this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getConfig() {\n    const config = super.getConfig();\n    delete config['rank'];\n    delete config['dataFormat'];\n    return config;\n  }\n\n  static verifyArgs(args) {\n    // config.kernelSize must be a number or array of numbers.\n    if (typeof args.kernelSize !== 'number' && !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 1)) {\n      throw new ValueError(\"Conv1D expects config.kernelSize to be number or number[] with \" + \"length 1, but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n    }\n  }\n\n}\n/** @nocollapse */\n\nConv1D.className = 'Conv1D';\nserialization.registerClass(Conv1D);\nexport class Cropping2D extends Layer {\n  constructor(args) {\n    super(args);\n\n    if (typeof args.cropping === 'number') {\n      this.cropping = [[args.cropping, args.cropping], [args.cropping, args.cropping]];\n    } else if (typeof args.cropping[0] === 'number') {\n      this.cropping = [[args.cropping[0], args.cropping[0]], [args.cropping[1], args.cropping[1]]];\n    } else {\n      this.cropping = args.cropping;\n    }\n\n    this.dataFormat = args.dataFormat === undefined ? 'channelsLast' : args.dataFormat;\n    this.inputSpec = [{\n      ndim: 4\n    }];\n  }\n\n  computeOutputShape(inputShape) {\n    if (this.dataFormat === 'channelsFirst') {\n      return [inputShape[0], inputShape[1], inputShape[2] - this.cropping[0][0] - this.cropping[0][1], inputShape[3] - this.cropping[1][0] - this.cropping[1][1]];\n    } else {\n      return [inputShape[0], inputShape[1] - this.cropping[0][0] - this.cropping[0][1], inputShape[2] - this.cropping[1][0] - this.cropping[1][1], inputShape[3]];\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n\n      if (this.dataFormat === 'channelsLast') {\n        const hSliced = K.sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);\n        return K.sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);\n      } else {\n        const hSliced = K.sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);\n        return K.sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);\n      }\n    });\n  }\n\n  getConfig() {\n    const config = {\n      cropping: this.cropping,\n      dataFormat: this.dataFormat\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nCropping2D.className = 'Cropping2D';\nserialization.registerClass(Cropping2D);\nexport class UpSampling2D extends Layer {\n  constructor(args) {\n    super(args);\n    this.DEFAULT_SIZE = [2, 2];\n    this.inputSpec = [{\n      ndim: 4\n    }];\n    this.size = args.size == null ? this.DEFAULT_SIZE : args.size;\n    this.dataFormat = args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n  }\n\n  computeOutputShape(inputShape) {\n    if (this.dataFormat === 'channelsFirst') {\n      const height = inputShape[2] == null ? null : this.size[0] * inputShape[2];\n      const width = inputShape[3] == null ? null : this.size[1] * inputShape[3];\n      return [inputShape[0], inputShape[1], height, width];\n    } else {\n      const height = inputShape[1] == null ? null : this.size[0] * inputShape[1];\n      const width = inputShape[2] == null ? null : this.size[1] * inputShape[2];\n      return [inputShape[0], height, width, inputShape[3]];\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tfc.tidy(() => {\n      let input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n\n      if (this.dataFormat === 'channelsFirst') {\n        input = tfc.transpose(input, [0, 2, 3, 1]);\n        const height = this.size[0] * inputShape[2];\n        const width = this.size[1] * inputShape[3];\n        const resized = input.resizeNearestNeighbor([height, width]);\n        return tfc.transpose(resized, [0, 3, 1, 2]);\n      } else {\n        const height = this.size[0] * inputShape[1];\n        const width = this.size[1] * inputShape[2];\n        return input.resizeNearestNeighbor([height, width]);\n      }\n    });\n  }\n\n  getConfig() {\n    const config = {\n      size: this.size,\n      dataFormat: this.dataFormat\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nUpSampling2D.className = 'UpSampling2D';\nserialization.registerClass(UpSampling2D);","map":null,"metadata":{},"sourceType":"module"}