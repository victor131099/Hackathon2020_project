{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => \"batchSize is required to be a positive integer, but got \".concat(batchSize));\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\n\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\n\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(array => sliceArraysByIndices(array, indices));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\n\nexport function makeBatches(size, batchSize) {\n  const output = [];\n  let batchStart = 0;\n  let batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\n\nasync function fitLoop( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n  if (batchSize == null) {\n    batchSize = 32;\n  }\n\n  if (epochs == null) {\n    epochs = 1;\n  }\n\n  if (shuffle == null) {\n    shuffle = true;\n  }\n\n  if (initialEpoch == null) {\n    initialEpoch = 0;\n  } // TODO(cais): Change const to let below when implementing validation.\n\n\n  let doValidation = false;\n\n  if (valF != null && valIns != null) {\n    doValidation = true; // TODO(cais): verbose message.\n  }\n\n  if (validationSteps != null) {\n    doValidation = true;\n\n    if (stepsPerEpoch == null) {\n      throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n    }\n  }\n\n  const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n  let indexArray;\n\n  if (numTrainSamples != null) {\n    indexArray = range(0, numTrainSamples);\n  }\n\n  if (verbose == null) {\n    verbose = 1;\n  }\n\n  const _configureCallbacks = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics),\n        callbackList = _configureCallbacks.callbackList,\n        history = _configureCallbacks.history;\n\n  callbackList.setModel(model);\n  model.history = history;\n  await callbackList.onTrainBegin();\n  model.stopTraining_ = false; // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n  // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n\n  for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n    await callbackList.onEpochBegin(epoch);\n    const epochLogs = {};\n\n    if (stepsPerEpoch != null) {\n      throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n    } else {\n      if (shuffle === 'batch') {\n        throw new NotImplementedError('batch shuffling is not implemneted yet');\n      } else if (shuffle) {\n        util.shuffle(indexArray);\n      } // Convert the potentially shuffled indices to Tensor1D, to avoid the\n      // cost of repeated creation of Array1Ds later on.\n\n\n      const epochIndexArray1D = tensor1d(indexArray);\n      const batches = makeBatches(numTrainSamples, batchSize);\n\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchLogs = {};\n        await callbackList.onBatchBegin(batchIndex, batchLogs);\n        tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n          batchLogs['batch'] = batchIndex;\n          batchLogs['size'] = batchEnd - batchStart; // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n\n          const insBatch = sliceArraysByIndices(ins, batchIds);\n          const outs = f(insBatch);\n\n          for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            const out = outs[i];\n            batchLogs[label] = out;\n            tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n          }\n\n          if (batchIndex === batches.length - 1) {\n            // Last batch.\n            if (doValidation) {\n              const valOuts = model.testLoop(valF, valIns, batchSize); // Porting Notes: In tfjs-layers, valOuts is always an Array.\n\n              for (let i = 0; i < outLabels.length; ++i) {\n                const label = outLabels[i];\n                const out = valOuts[i];\n                tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n\n                epochLogs['val_' + label] = out;\n              }\n            }\n          }\n        });\n        await callbackList.onBatchEnd(batchIndex, batchLogs);\n        disposeTensorsInLogs(batchLogs);\n\n        if (model.stopTraining_) {\n          break;\n        } // TODO(cais): return outs as list of Tensor.\n\n      }\n\n      epochIndexArray1D.dispose();\n    } // TODO(cais): Run validation at the end of the epoch.\n\n\n    await callbackList.onEpochEnd(epoch, epochLogs);\n\n    if (model.stopTraining_) {\n      break;\n    }\n  }\n\n  await callbackList.onTrainEnd();\n  await model.history.syncData();\n  return model.history;\n}\n\nexport async function fitTensors( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n  if (model.isTraining) {\n    throw new Error('Cannot start training because another fit() call is ongoing.');\n  }\n\n  model.isTraining = true;\n  let inputs;\n  let targets;\n  let inputValX;\n  let inputValY;\n  let valX;\n  let valY;\n  let sampleWeights;\n\n  try {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize); // Validate user data.\n    // TODO(cais): Support sampleWeight.\n\n    const checkBatchAxis = false;\n    const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n    inputs = standardizedOuts[0];\n    targets = standardizedOuts[1];\n    sampleWeights = standardizedOuts[2]; // Prepare validation data.\n\n    let doValidation = false;\n    let valIns;\n\n    if (args.validationData != null && args.validationData.length > 0) {\n      doValidation = true;\n\n      if (args.validationData.length === 2) {\n        // config.validationData consists of valX and valY.\n        inputValX = args.validationData[0];\n        inputValY = args.validationData[1];\n      } else if (args.validationData.length === 3) {\n        throw new NotImplementedError('validationData including sample weights is not supported yet.');\n      } else {\n        throw new ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" + \"or 3 (valX, valY, valSampleWeight) items; \" + \"\".concat(args.validationData, \" is invalid.\"));\n      }\n\n      const checkBatchAxis = true;\n      const valStandardized = await model.standardizeUserData(inputValX, inputValY, null,\n      /** Unused sample weights. */\n      null,\n      /** Unused class weights. */\n      checkBatchAxis, batchSize);\n      valX = valStandardized[0];\n      valY = valStandardized[1];\n      valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n      doValidation = true; // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n\n      const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n      const originalBatchSize = inputs[0].shape[0];\n      valX = sliceArrays(inputs, splitAt, originalBatchSize);\n      inputs = sliceArrays(inputs, 0, splitAt);\n      valY = sliceArrays(targets, splitAt, originalBatchSize);\n      targets = sliceArrays(targets, 0, splitAt); // TODO(cais): Once sampleWeights becomes available, slice it to get\n      //   valSampleWeights.\n\n      valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSteps != null) {\n      doValidation = true; // TODO(cais): Add useLearningPhase.\n    }\n\n    const ins = inputs.concat(targets).concat(sampleWeights);\n    model.checkTrainableWeightsConsistency(); // TODO(cais): Handle use_learning_phase and learning_phase?\n    // Porting Note: Here we see a key deviation of tfjs-layers from\n    // Keras.\n    //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n    //  we do not construct symbolic computation graphs to embody the\n    //  training process. Instead, we define a function that performs the\n    //  training action. In PyKeras, the data (inputs and targets) are fed\n    //  through graph placeholders. In tfjs-layers, the data are fed as\n    //  function arguments. Since the function are defined below in the\n    //  scope, we don't have equivalents of PyKeras's\n    //  `_make_train_funciton`.\n\n    const trainFunction = model.makeTrainFunction();\n    const outLabels = model.getDedupedMetricsNames();\n    let valFunction;\n    let callbackMetrics;\n\n    if (doValidation) {\n      model.makeTestFunction();\n      valFunction = model.testFunction;\n      callbackMetrics = outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n    } else {\n      valFunction = null;\n      valIns = [];\n      callbackMetrics = outLabels.slice();\n    }\n\n    const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n    const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n    return out;\n  } finally {\n    model.isTraining = false; // Memory clean up.\n\n    disposeNewTensors(inputs, x);\n    disposeNewTensors(targets, y);\n    disposeNewTensors(valX, inputValX);\n    disposeNewTensors(valY, inputValY);\n\n    if (sampleWeights != null) {\n      tfc.dispose(sampleWeights);\n    }\n  } // TODO(cais): Add value to outLabels.\n\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\n\nexport function ensureTensorsRank2OrHigher(tensors) {\n  const outs = [];\n\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  } // Make Tensors at least 2D.\n\n\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\n\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n\n  const oldTensorIds = [];\n\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  const tensorsToDispose = [];\n\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":null,"metadata":{},"sourceType":"module"}