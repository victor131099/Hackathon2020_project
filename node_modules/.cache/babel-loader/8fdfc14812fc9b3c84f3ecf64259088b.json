{"ast":null,"code":"\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n\n    return extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function () {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n\n        case 7:\n          op = _.ops.pop();\n\n          _.trys.pop();\n\n          continue;\n\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n\n            _.ops.push(op);\n\n            break;\n          }\n\n          if (t[2]) _.ops.pop();\n\n          _.trys.pop();\n\n          continue;\n      }\n\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\n\nvar path = require(\"path\");\n\nvar ProgressBar = require(\"progress\");\n\nvar tensorboard_1 = require(\"./tensorboard\"); // A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\n\n\nexports.progressBarHelper = {\n  ProgressBar: ProgressBar,\n  log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\n\nvar ProgbarLogger =\n/** @class */\nfunction (_super) {\n  __extends(ProgbarLogger, _super);\n  /**\n   * Construtor of LoggingCallback.\n   */\n\n\n  function ProgbarLogger() {\n    var _this = _super.call(this, {\n      onTrainBegin: function (logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var samples, batchSize, steps;\n          return __generator(this, function (_a) {\n            samples = this.params.samples;\n            batchSize = this.params.batchSize;\n            steps = this.params.steps;\n\n            if (samples != null || steps != null) {\n              this.numTrainBatchesPerEpoch = samples != null ? Math.ceil(samples / batchSize) : steps;\n            } else {\n              // Undetermined number of batches per epoch, e.g., due to\n              // `fitDataset()` without `batchesPerEpoch`.\n              this.numTrainBatchesPerEpoch = 0;\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onEpochBegin: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            exports.progressBarHelper.log(\"Epoch \" + (epoch + 1) + \" / \" + this.params.epochs);\n            this.currentEpochBegin = tfjs_1.util.now();\n            this.epochDurationMillis = null;\n            this.usPerStep = null;\n            this.batchesInLatestEpoch = 0;\n            this.terminalWidth = process.stderr.columns;\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onBatchEnd: function (batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var maxMetricsStringLength, tickTokens;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                this.batchesInLatestEpoch++;\n\n                if (batch === 0) {\n                  this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                    width: Math.floor(0.5 * this.terminalWidth),\n                    total: this.numTrainBatchesPerEpoch + 1,\n                    head: \">\",\n                    renderThrottle: this.RENDER_THROTTLE_MS\n                  });\n                }\n\n                maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                tickTokens = {\n                  placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                };\n\n                if (this.numTrainBatchesPerEpoch === 0) {\n                  // Undetermined number of batches per epoch.\n                  this.progressBar.tick(0, tickTokens);\n                } else {\n                  this.progressBar.tick(tickTokens);\n                }\n\n                return [4\n                /*yield*/\n                , tfjs_1.nextFrame()];\n\n              case 1:\n                _a.sent();\n\n                if (batch === this.numTrainBatchesPerEpoch - 1) {\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.params.samples != null ? this.epochDurationMillis / this.params.samples * 1e3 : this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n\n                return [2\n                /*return*/\n                ];\n            }\n          });\n        });\n      },\n      onEpochEnd: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var lossesAndMetricsString;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                if (this.epochDurationMillis == null) {\n                  // In cases where the number of batches per epoch is not determined,\n                  // the calculation of the per-step duration is done at the end of the\n                  // epoch. N.B., this includes the time spent on validation.\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n\n                this.progressBar.tick({\n                  placeholderForLossesAndMetrics: ''\n                });\n                lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                exports.progressBarHelper.log(this.epochDurationMillis.toFixed(0) + \"ms \" + (this.usPerStep.toFixed(0) + \"us/step - \") + (\"\" + lossesAndMetricsString));\n                return [4\n                /*yield*/\n                , tfjs_1.nextFrame()];\n\n              case 1:\n                _a.sent();\n\n                return [2\n                /*return*/\n                ];\n            }\n          });\n        });\n      }\n    }) || this;\n\n    _this.RENDER_THROTTLE_MS = 50;\n    return _this;\n  }\n\n  ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n    var metricsContent = '';\n    var keys = Object.keys(logs).sort();\n\n    for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n      var key = keys_1[_i];\n\n      if (this.isFieldRelevant(key)) {\n        var value = logs[key];\n        metricsContent += key + \"=\" + getSuccinctNumberDisplay(value) + \" \";\n      }\n    }\n\n    if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n      // Cut off metrics strings that are too long to avoid new lines being\n      // constantly created.\n      metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n    }\n\n    return metricsContent;\n  };\n\n  ProgbarLogger.prototype.isFieldRelevant = function (key) {\n    return key !== 'batch' && key !== 'size';\n  };\n\n  return ProgbarLogger;\n}(tfjs_1.CustomCallback);\n\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\n\nfunction getSuccinctNumberDisplay(x) {\n  var decimalPlaces = getDisplayDecimalPlaces(x);\n  return decimalPlaces > MAX_NUM_DECIMAL_PLACES ? x.toExponential(BASE_NUM_DIGITS) : x.toFixed(decimalPlaces);\n}\n\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\n\nfunction getDisplayDecimalPlaces(x) {\n  if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n    return BASE_NUM_DIGITS;\n  } else {\n    return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n  }\n}\n\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\n\nvar TensorBoardCallback =\n/** @class */\nfunction (_super) {\n  __extends(TensorBoardCallback, _super);\n\n  function TensorBoardCallback(logdir, args) {\n    if (logdir === void 0) {\n      logdir = './logs';\n    }\n\n    var _this = _super.call(this, {\n      onBatchEnd: function (batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.batchesSeen++;\n\n            if (this.args.updateFreq !== 'epoch') {\n              this.logMetrics(logs, 'batch_', this.batchesSeen);\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onEpochEnd: function (epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.logMetrics(logs, 'epoch_', epoch + 1);\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onTrainEnd: function (logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            if (this.trainWriter != null) {\n              this.trainWriter.flush();\n            }\n\n            if (this.valWriter != null) {\n              this.valWriter.flush();\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      }\n    }) || this;\n\n    _this.logdir = logdir;\n    _this.args = args == null ? {} : args;\n\n    if (_this.args.updateFreq == null) {\n      _this.args.updateFreq = 'epoch';\n    }\n\n    tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () {\n      return \"Expected updateFreq to be 'batch' or 'epoch', but got \" + (\"\" + _this.args.updateFreq);\n    });\n    _this.batchesSeen = 0;\n    return _this;\n  }\n\n  TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n    for (var key in logs) {\n      if (key === 'batch' || key === 'size' || key === 'num_steps') {\n        continue;\n      }\n\n      var VAL_PREFIX = 'val_';\n\n      if (key.startsWith(VAL_PREFIX)) {\n        this.ensureValWriterCreated();\n        var scalarName = prefix + key.slice(VAL_PREFIX.length);\n        this.valWriter.scalar(scalarName, logs[key], step);\n      } else {\n        this.ensureTrainWriterCreated();\n        this.trainWriter.scalar(\"\" + prefix + key, logs[key], step);\n      }\n    }\n  };\n\n  TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n    this.trainWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'train'));\n  };\n\n  TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n    this.valWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'val'));\n  };\n\n  return TensorBoardCallback;\n}(tfjs_1.CustomCallback);\n\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n */\n\n/**\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\n\nfunction tensorBoard(logdir, args) {\n  if (logdir === void 0) {\n    logdir = './logs';\n  }\n\n  return new TensorBoardCallback(logdir, args);\n}\n\nexports.tensorBoard = tensorBoard;","map":{"version":3,"sources":["/home/victor/COVID-19-Coding-Fest/node_modules/@tensorflow/tfjs-node-gpu/dist/callbacks.js"],"names":["__extends","extendStatics","d","b","Object","setPrototypeOf","__proto__","Array","p","hasOwnProperty","__","constructor","prototype","create","__awaiter","thisArg","_arguments","P","generator","Promise","resolve","reject","fulfilled","value","step","next","e","rejected","result","done","then","apply","__generator","body","_","label","sent","t","trys","ops","f","y","g","verb","Symbol","iterator","n","v","op","TypeError","call","pop","length","push","defineProperty","exports","tfjs_1","require","path","ProgressBar","tensorboard_1","progressBarHelper","log","console","ProgbarLogger","_super","_this","onTrainBegin","logs","samples","batchSize","steps","_a","params","numTrainBatchesPerEpoch","Math","ceil","onEpochBegin","epoch","epochs","currentEpochBegin","util","now","epochDurationMillis","usPerStep","batchesInLatestEpoch","terminalWidth","process","stderr","columns","onBatchEnd","batch","maxMetricsStringLength","tickTokens","progressBar","width","floor","total","head","renderThrottle","RENDER_THROTTLE_MS","placeholderForLossesAndMetrics","formatLogsAsMetricsContent","tick","nextFrame","onEpochEnd","lossesAndMetricsString","toFixed","maxMetricsLength","metricsContent","keys","sort","_i","keys_1","key","isFieldRelevant","getSuccinctNumberDisplay","slice","CustomCallback","BASE_NUM_DIGITS","MAX_NUM_DECIMAL_PLACES","x","decimalPlaces","getDisplayDecimalPlaces","toExponential","Number","isFinite","log10","abs","TensorBoardCallback","logdir","args","batchesSeen","updateFreq","logMetrics","onTrainEnd","trainWriter","flush","valWriter","assert","indexOf","prefix","VAL_PREFIX","startsWith","ensureValWriterCreated","scalarName","scalar","ensureTrainWriterCreated","summaryFileWriter","join","tensorBoard"],"mappings":"AAAA;AACA;;;;;;;;;;;;;;;;;AAgBA,IAAIA,SAAS,GAAI,QAAQ,KAAKA,SAAd,IAA6B,YAAY;AACrD,MAAIC,aAAa,GAAG,UAAUC,CAAV,EAAaC,CAAb,EAAgB;AAChCF,IAAAA,aAAa,GAAGG,MAAM,CAACC,cAAP,IACX;AAAEC,MAAAA,SAAS,EAAE;AAAb,iBAA6BC,KAA7B,IAAsC,UAAUL,CAAV,EAAaC,CAAb,EAAgB;AAAED,MAAAA,CAAC,CAACI,SAAF,GAAcH,CAAd;AAAkB,KAD/D,IAEZ,UAAUD,CAAV,EAAaC,CAAb,EAAgB;AAAE,WAAK,IAAIK,CAAT,IAAcL,CAAd,EAAiB,IAAIA,CAAC,CAACM,cAAF,CAAiBD,CAAjB,CAAJ,EAAyBN,CAAC,CAACM,CAAD,CAAD,GAAOL,CAAC,CAACK,CAAD,CAAR;AAAc,KAF9E;;AAGA,WAAOP,aAAa,CAACC,CAAD,EAAIC,CAAJ,CAApB;AACH,GALD;;AAMA,SAAO,UAAUD,CAAV,EAAaC,CAAb,EAAgB;AACnBF,IAAAA,aAAa,CAACC,CAAD,EAAIC,CAAJ,CAAb;;AACA,aAASO,EAAT,GAAc;AAAE,WAAKC,WAAL,GAAmBT,CAAnB;AAAuB;;AACvCA,IAAAA,CAAC,CAACU,SAAF,GAAcT,CAAC,KAAK,IAAN,GAAaC,MAAM,CAACS,MAAP,CAAcV,CAAd,CAAb,IAAiCO,EAAE,CAACE,SAAH,GAAeT,CAAC,CAACS,SAAjB,EAA4B,IAAIF,EAAJ,EAA7D,CAAd;AACH,GAJD;AAKH,CAZ2C,EAA5C;;AAaA,IAAII,SAAS,GAAI,QAAQ,KAAKA,SAAd,IAA4B,UAAUC,OAAV,EAAmBC,UAAnB,EAA+BC,CAA/B,EAAkCC,SAAlC,EAA6C;AACrF,SAAO,KAAKD,CAAC,KAAKA,CAAC,GAAGE,OAAT,CAAN,EAAyB,UAAUC,OAAV,EAAmBC,MAAnB,EAA2B;AACvD,aAASC,SAAT,CAAmBC,KAAnB,EAA0B;AAAE,UAAI;AAAEC,QAAAA,IAAI,CAACN,SAAS,CAACO,IAAV,CAAeF,KAAf,CAAD,CAAJ;AAA8B,OAApC,CAAqC,OAAOG,CAAP,EAAU;AAAEL,QAAAA,MAAM,CAACK,CAAD,CAAN;AAAY;AAAE;;AAC3F,aAASC,QAAT,CAAkBJ,KAAlB,EAAyB;AAAE,UAAI;AAAEC,QAAAA,IAAI,CAACN,SAAS,CAAC,OAAD,CAAT,CAAmBK,KAAnB,CAAD,CAAJ;AAAkC,OAAxC,CAAyC,OAAOG,CAAP,EAAU;AAAEL,QAAAA,MAAM,CAACK,CAAD,CAAN;AAAY;AAAE;;AAC9F,aAASF,IAAT,CAAcI,MAAd,EAAsB;AAAEA,MAAAA,MAAM,CAACC,IAAP,GAAcT,OAAO,CAACQ,MAAM,CAACL,KAAR,CAArB,GAAsC,IAAIN,CAAJ,CAAM,UAAUG,OAAV,EAAmB;AAAEA,QAAAA,OAAO,CAACQ,MAAM,CAACL,KAAR,CAAP;AAAwB,OAAnD,EAAqDO,IAArD,CAA0DR,SAA1D,EAAqEK,QAArE,CAAtC;AAAuH;;AAC/IH,IAAAA,IAAI,CAAC,CAACN,SAAS,GAAGA,SAAS,CAACa,KAAV,CAAgBhB,OAAhB,EAAyBC,UAAU,IAAI,EAAvC,CAAb,EAAyDS,IAAzD,EAAD,CAAJ;AACH,GALM,CAAP;AAMH,CAPD;;AAQA,IAAIO,WAAW,GAAI,QAAQ,KAAKA,WAAd,IAA8B,UAAUjB,OAAV,EAAmBkB,IAAnB,EAAyB;AACrE,MAAIC,CAAC,GAAG;AAAEC,IAAAA,KAAK,EAAE,CAAT;AAAYC,IAAAA,IAAI,EAAE,YAAW;AAAE,UAAIC,CAAC,CAAC,CAAD,CAAD,GAAO,CAAX,EAAc,MAAMA,CAAC,CAAC,CAAD,CAAP;AAAY,aAAOA,CAAC,CAAC,CAAD,CAAR;AAAc,KAAvE;AAAyEC,IAAAA,IAAI,EAAE,EAA/E;AAAmFC,IAAAA,GAAG,EAAE;AAAxF,GAAR;AAAA,MAAsGC,CAAtG;AAAA,MAAyGC,CAAzG;AAAA,MAA4GJ,CAA5G;AAAA,MAA+GK,CAA/G;AACA,SAAOA,CAAC,GAAG;AAAEjB,IAAAA,IAAI,EAAEkB,IAAI,CAAC,CAAD,CAAZ;AAAiB,aAASA,IAAI,CAAC,CAAD,CAA9B;AAAmC,cAAUA,IAAI,CAAC,CAAD;AAAjD,GAAJ,EAA4D,OAAOC,MAAP,KAAkB,UAAlB,KAAiCF,CAAC,CAACE,MAAM,CAACC,QAAR,CAAD,GAAqB,YAAW;AAAE,WAAO,IAAP;AAAc,GAAjF,CAA5D,EAAgJH,CAAvJ;;AACA,WAASC,IAAT,CAAcG,CAAd,EAAiB;AAAE,WAAO,UAAUC,CAAV,EAAa;AAAE,aAAOvB,IAAI,CAAC,CAACsB,CAAD,EAAIC,CAAJ,CAAD,CAAX;AAAsB,KAA5C;AAA+C;;AAClE,WAASvB,IAAT,CAAcwB,EAAd,EAAkB;AACd,QAAIR,CAAJ,EAAO,MAAM,IAAIS,SAAJ,CAAc,iCAAd,CAAN;;AACP,WAAOf,CAAP,EAAU,IAAI;AACV,UAAIM,CAAC,GAAG,CAAJ,EAAOC,CAAC,KAAKJ,CAAC,GAAGW,EAAE,CAAC,CAAD,CAAF,GAAQ,CAAR,GAAYP,CAAC,CAAC,QAAD,CAAb,GAA0BO,EAAE,CAAC,CAAD,CAAF,GAAQP,CAAC,CAAC,OAAD,CAAD,KAAe,CAACJ,CAAC,GAAGI,CAAC,CAAC,QAAD,CAAN,KAAqBJ,CAAC,CAACa,IAAF,CAAOT,CAAP,CAArB,EAAgC,CAA/C,CAAR,GAA4DA,CAAC,CAAChB,IAAjG,CAAD,IAA2G,CAAC,CAACY,CAAC,GAAGA,CAAC,CAACa,IAAF,CAAOT,CAAP,EAAUO,EAAE,CAAC,CAAD,CAAZ,CAAL,EAAuBnB,IAA9I,EAAoJ,OAAOQ,CAAP;AACpJ,UAAII,CAAC,GAAG,CAAJ,EAAOJ,CAAX,EAAcW,EAAE,GAAG,CAACA,EAAE,CAAC,CAAD,CAAF,GAAQ,CAAT,EAAYX,CAAC,CAACd,KAAd,CAAL;;AACd,cAAQyB,EAAE,CAAC,CAAD,CAAV;AACI,aAAK,CAAL;AAAQ,aAAK,CAAL;AAAQX,UAAAA,CAAC,GAAGW,EAAJ;AAAQ;;AACxB,aAAK,CAAL;AAAQd,UAAAA,CAAC,CAACC,KAAF;AAAW,iBAAO;AAAEZ,YAAAA,KAAK,EAAEyB,EAAE,CAAC,CAAD,CAAX;AAAgBnB,YAAAA,IAAI,EAAE;AAAtB,WAAP;;AACnB,aAAK,CAAL;AAAQK,UAAAA,CAAC,CAACC,KAAF;AAAWM,UAAAA,CAAC,GAAGO,EAAE,CAAC,CAAD,CAAN;AAAWA,UAAAA,EAAE,GAAG,CAAC,CAAD,CAAL;AAAU;;AACxC,aAAK,CAAL;AAAQA,UAAAA,EAAE,GAAGd,CAAC,CAACK,GAAF,CAAMY,GAAN,EAAL;;AAAkBjB,UAAAA,CAAC,CAACI,IAAF,CAAOa,GAAP;;AAAc;;AACxC;AACI,cAAI,EAAEd,CAAC,GAAGH,CAAC,CAACI,IAAN,EAAYD,CAAC,GAAGA,CAAC,CAACe,MAAF,GAAW,CAAX,IAAgBf,CAAC,CAACA,CAAC,CAACe,MAAF,GAAW,CAAZ,CAAnC,MAAuDJ,EAAE,CAAC,CAAD,CAAF,KAAU,CAAV,IAAeA,EAAE,CAAC,CAAD,CAAF,KAAU,CAAhF,CAAJ,EAAwF;AAAEd,YAAAA,CAAC,GAAG,CAAJ;AAAO;AAAW;;AAC5G,cAAIc,EAAE,CAAC,CAAD,CAAF,KAAU,CAAV,KAAgB,CAACX,CAAD,IAAOW,EAAE,CAAC,CAAD,CAAF,GAAQX,CAAC,CAAC,CAAD,CAAT,IAAgBW,EAAE,CAAC,CAAD,CAAF,GAAQX,CAAC,CAAC,CAAD,CAAhD,CAAJ,EAA2D;AAAEH,YAAAA,CAAC,CAACC,KAAF,GAAUa,EAAE,CAAC,CAAD,CAAZ;AAAiB;AAAQ;;AACtF,cAAIA,EAAE,CAAC,CAAD,CAAF,KAAU,CAAV,IAAed,CAAC,CAACC,KAAF,GAAUE,CAAC,CAAC,CAAD,CAA9B,EAAmC;AAAEH,YAAAA,CAAC,CAACC,KAAF,GAAUE,CAAC,CAAC,CAAD,CAAX;AAAgBA,YAAAA,CAAC,GAAGW,EAAJ;AAAQ;AAAQ;;AACrE,cAAIX,CAAC,IAAIH,CAAC,CAACC,KAAF,GAAUE,CAAC,CAAC,CAAD,CAApB,EAAyB;AAAEH,YAAAA,CAAC,CAACC,KAAF,GAAUE,CAAC,CAAC,CAAD,CAAX;;AAAgBH,YAAAA,CAAC,CAACK,GAAF,CAAMc,IAAN,CAAWL,EAAX;;AAAgB;AAAQ;;AACnE,cAAIX,CAAC,CAAC,CAAD,CAAL,EAAUH,CAAC,CAACK,GAAF,CAAMY,GAAN;;AACVjB,UAAAA,CAAC,CAACI,IAAF,CAAOa,GAAP;;AAAc;AAXtB;;AAaAH,MAAAA,EAAE,GAAGf,IAAI,CAACiB,IAAL,CAAUnC,OAAV,EAAmBmB,CAAnB,CAAL;AACH,KAjBS,CAiBR,OAAOR,CAAP,EAAU;AAAEsB,MAAAA,EAAE,GAAG,CAAC,CAAD,EAAItB,CAAJ,CAAL;AAAae,MAAAA,CAAC,GAAG,CAAJ;AAAQ,KAjBzB,SAiBkC;AAAED,MAAAA,CAAC,GAAGH,CAAC,GAAG,CAAR;AAAY;;AAC1D,QAAIW,EAAE,CAAC,CAAD,CAAF,GAAQ,CAAZ,EAAe,MAAMA,EAAE,CAAC,CAAD,CAAR;AAAa,WAAO;AAAEzB,MAAAA,KAAK,EAAEyB,EAAE,CAAC,CAAD,CAAF,GAAQA,EAAE,CAAC,CAAD,CAAV,GAAgB,KAAK,CAA9B;AAAiCnB,MAAAA,IAAI,EAAE;AAAvC,KAAP;AAC/B;AACJ,CA1BD;;AA2BAzB,MAAM,CAACkD,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEhC,EAAAA,KAAK,EAAE;AAAT,CAA7C;;AACA,IAAIiC,MAAM,GAAGC,OAAO,CAAC,kBAAD,CAApB;;AACA,IAAIC,IAAI,GAAGD,OAAO,CAAC,MAAD,CAAlB;;AACA,IAAIE,WAAW,GAAGF,OAAO,CAAC,UAAD,CAAzB;;AACA,IAAIG,aAAa,GAAGH,OAAO,CAAC,eAAD,CAA3B,C,CACA;AACA;AACA;;;AACAF,OAAO,CAACM,iBAAR,GAA4B;AACxBF,EAAAA,WAAW,EAAEA,WADW;AAExBG,EAAAA,GAAG,EAAEC,OAAO,CAACD;AAFW,CAA5B;AAIA;;;;AAGA,IAAIE,aAAa;AAAG;AAAe,UAAUC,MAAV,EAAkB;AACjDjE,EAAAA,SAAS,CAACgE,aAAD,EAAgBC,MAAhB,CAAT;AACA;;;;;AAGA,WAASD,aAAT,GAAyB;AACrB,QAAIE,KAAK,GAAGD,MAAM,CAACf,IAAP,CAAY,IAAZ,EAAkB;AAC1BiB,MAAAA,YAAY,EAAE,UAAUC,IAAV,EAAgB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AAChF,cAAIG,OAAJ,EAAaC,SAAb,EAAwBC,KAAxB;AACA,iBAAOvC,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnCH,YAAAA,OAAO,GAAG,KAAKI,MAAL,CAAYJ,OAAtB;AACAC,YAAAA,SAAS,GAAG,KAAKG,MAAL,CAAYH,SAAxB;AACAC,YAAAA,KAAK,GAAG,KAAKE,MAAL,CAAYF,KAApB;;AACA,gBAAIF,OAAO,IAAI,IAAX,IAAmBE,KAAK,IAAI,IAAhC,EAAsC;AAClC,mBAAKG,uBAAL,GACIL,OAAO,IAAI,IAAX,GAAkBM,IAAI,CAACC,IAAL,CAAUP,OAAO,GAAGC,SAApB,CAAlB,GAAmDC,KADvD;AAEH,aAHD,MAIK;AACD;AACA;AACA,mBAAKG,uBAAL,GAA+B,CAA/B;AACH;;AACD,mBAAO,CAAC;AAAE;AAAH,aAAP;AACH,WAdiB,CAAlB;AAeH,SAjB+C,CAAhB;AAiB3B,OAlBqB;AAmB1BG,MAAAA,YAAY,EAAE,UAAUC,KAAV,EAAiBV,IAAjB,EAAuB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AACvF,iBAAOlC,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnCjB,YAAAA,OAAO,CAACM,iBAAR,CAA0BC,GAA1B,CAA8B,YAAYgB,KAAK,GAAG,CAApB,IAAyB,KAAzB,GAAiC,KAAKL,MAAL,CAAYM,MAA3E;AACA,iBAAKC,iBAAL,GAAyBxB,MAAM,CAACyB,IAAP,CAAYC,GAAZ,EAAzB;AACA,iBAAKC,mBAAL,GAA2B,IAA3B;AACA,iBAAKC,SAAL,GAAiB,IAAjB;AACA,iBAAKC,oBAAL,GAA4B,CAA5B;AACA,iBAAKC,aAAL,GAAqBC,OAAO,CAACC,MAAR,CAAeC,OAApC;AACA,mBAAO,CAAC;AAAE;AAAH,aAAP;AACH,WARiB,CAAlB;AASH,SAVsD,CAAhB;AAUlC,OA7BqB;AA8B1BC,MAAAA,UAAU,EAAE,UAAUC,KAAV,EAAiBvB,IAAjB,EAAuB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AACrF,cAAI0B,sBAAJ,EAA4BC,UAA5B;AACA,iBAAO7D,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnC,oBAAQA,EAAE,CAACrC,KAAX;AACI,mBAAK,CAAL;AACI,qBAAKkD,oBAAL;;AACA,oBAAIM,KAAK,KAAK,CAAd,EAAiB;AACb,uBAAKG,WAAL,GAAmB,IAAIvC,OAAO,CAACM,iBAAR,CAA0BF,WAA9B,CAA0C,+CAA1C,EAA2F;AAC1GoC,oBAAAA,KAAK,EAAEpB,IAAI,CAACqB,KAAL,CAAW,MAAM,KAAKV,aAAtB,CADmG;AAE1GW,oBAAAA,KAAK,EAAE,KAAKvB,uBAAL,GAA+B,CAFoE;AAG1GwB,oBAAAA,IAAI,EAAE,GAHoG;AAI1GC,oBAAAA,cAAc,EAAE,KAAKC;AAJqF,mBAA3F,CAAnB;AAMH;;AACDR,gBAAAA,sBAAsB,GAAGjB,IAAI,CAACqB,KAAL,CAAW,KAAKV,aAAL,GAAqB,GAArB,GAA2B,EAAtC,CAAzB;AACAO,gBAAAA,UAAU,GAAG;AACTQ,kBAAAA,8BAA8B,EAAE,KAAKC,0BAAL,CAAgClC,IAAhC,EAAsCwB,sBAAtC;AADvB,iBAAb;;AAGA,oBAAI,KAAKlB,uBAAL,KAAiC,CAArC,EAAwC;AACpC;AACA,uBAAKoB,WAAL,CAAiBS,IAAjB,CAAsB,CAAtB,EAAyBV,UAAzB;AACH,iBAHD,MAIK;AACD,uBAAKC,WAAL,CAAiBS,IAAjB,CAAsBV,UAAtB;AACH;;AACD,uBAAO,CAAC;AAAE;AAAH,kBAAcrC,MAAM,CAACgD,SAAP,EAAd,CAAP;;AACJ,mBAAK,CAAL;AACIhC,gBAAAA,EAAE,CAACpC,IAAH;;AACA,oBAAIuD,KAAK,KAAK,KAAKjB,uBAAL,GAA+B,CAA7C,EAAgD;AAC5C,uBAAKS,mBAAL,GAA2B3B,MAAM,CAACyB,IAAP,CAAYC,GAAZ,KAAoB,KAAKF,iBAApD;AACA,uBAAKI,SAAL,GAAiB,KAAKX,MAAL,CAAYJ,OAAZ,IAAuB,IAAvB,GACb,KAAKc,mBAAL,GAA2B,KAAKV,MAAL,CAAYJ,OAAvC,GAAiD,GADpC,GAEb,KAAKc,mBAAL,GAA2B,KAAKE,oBAAhC,GAAuD,GAF3D;AAGH;;AACD,uBAAO,CAAC;AAAE;AAAH,iBAAP;AA/BR;AAiCH,WAlCiB,CAAlB;AAmCH,SArCoD,CAAhB;AAqChC,OAnEqB;AAoE1BoB,MAAAA,UAAU,EAAE,UAAU3B,KAAV,EAAiBV,IAAjB,EAAuB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AACrF,cAAIwC,sBAAJ;AACA,iBAAO1E,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnC,oBAAQA,EAAE,CAACrC,KAAX;AACI,mBAAK,CAAL;AACI,oBAAI,KAAKgD,mBAAL,IAA4B,IAAhC,EAAsC;AAClC;AACA;AACA;AACA,uBAAKA,mBAAL,GAA2B3B,MAAM,CAACyB,IAAP,CAAYC,GAAZ,KAAoB,KAAKF,iBAApD;AACA,uBAAKI,SAAL,GACI,KAAKD,mBAAL,GAA2B,KAAKE,oBAAhC,GAAuD,GAD3D;AAEH;;AACD,qBAAKS,WAAL,CAAiBS,IAAjB,CAAsB;AAAEF,kBAAAA,8BAA8B,EAAE;AAAlC,iBAAtB;AACAK,gBAAAA,sBAAsB,GAAG,KAAKJ,0BAAL,CAAgClC,IAAhC,CAAzB;AACAb,gBAAAA,OAAO,CAACM,iBAAR,CAA0BC,GAA1B,CAA8B,KAAKqB,mBAAL,CAAyBwB,OAAzB,CAAiC,CAAjC,IAAsC,KAAtC,IACzB,KAAKvB,SAAL,CAAeuB,OAAf,CAAuB,CAAvB,IAA4B,YADH,KAEzB,KAAKD,sBAFoB,CAA9B;AAGA,uBAAO,CAAC;AAAE;AAAH,kBAAclD,MAAM,CAACgD,SAAP,EAAd,CAAP;;AACJ,mBAAK,CAAL;AACIhC,gBAAAA,EAAE,CAACpC,IAAH;;AACA,uBAAO,CAAC;AAAE;AAAH,iBAAP;AAlBR;AAoBH,WArBiB,CAAlB;AAsBH,SAxBoD,CAAhB;AAwBhC;AA5FqB,KAAlB,KA6FN,IA7FN;;AA8FA8B,IAAAA,KAAK,CAACkC,kBAAN,GAA2B,EAA3B;AACA,WAAOlC,KAAP;AACH;;AACDF,EAAAA,aAAa,CAACpD,SAAd,CAAwB0F,0BAAxB,GAAqD,UAAUlC,IAAV,EAAgBwC,gBAAhB,EAAkC;AACnF,QAAIC,cAAc,GAAG,EAArB;AACA,QAAIC,IAAI,GAAG1G,MAAM,CAAC0G,IAAP,CAAY1C,IAAZ,EAAkB2C,IAAlB,EAAX;;AACA,SAAK,IAAIC,EAAE,GAAG,CAAT,EAAYC,MAAM,GAAGH,IAA1B,EAAgCE,EAAE,GAAGC,MAAM,CAAC7D,MAA5C,EAAoD4D,EAAE,EAAtD,EAA0D;AACtD,UAAIE,GAAG,GAAGD,MAAM,CAACD,EAAD,CAAhB;;AACA,UAAI,KAAKG,eAAL,CAAqBD,GAArB,CAAJ,EAA+B;AAC3B,YAAI3F,KAAK,GAAG6C,IAAI,CAAC8C,GAAD,CAAhB;AACAL,QAAAA,cAAc,IAAIK,GAAG,GAAG,GAAN,GAAYE,wBAAwB,CAAC7F,KAAD,CAApC,GAA8C,GAAhE;AACH;AACJ;;AACD,QAAIqF,gBAAgB,IAAI,IAApB,IAA4BC,cAAc,CAACzD,MAAf,GAAwBwD,gBAAxD,EAA0E;AACtE;AACA;AACAC,MAAAA,cAAc,GAAGA,cAAc,CAACQ,KAAf,CAAqB,CAArB,EAAwBT,gBAAgB,GAAG,CAA3C,IAAgD,KAAjE;AACH;;AACD,WAAOC,cAAP;AACH,GAhBD;;AAiBA7C,EAAAA,aAAa,CAACpD,SAAd,CAAwBuG,eAAxB,GAA0C,UAAUD,GAAV,EAAe;AACrD,WAAOA,GAAG,KAAK,OAAR,IAAmBA,GAAG,KAAK,MAAlC;AACH,GAFD;;AAGA,SAAOlD,aAAP;AACH,CA5HkC,CA4HjCR,MAAM,CAAC8D,cA5H0B,CAAnC;;AA6HA/D,OAAO,CAACS,aAAR,GAAwBA,aAAxB;AACA,IAAIuD,eAAe,GAAG,CAAtB;AACA,IAAIC,sBAAsB,GAAG,CAA7B;AACA;;;;;;;;;;AASA,SAASJ,wBAAT,CAAkCK,CAAlC,EAAqC;AACjC,MAAIC,aAAa,GAAGC,uBAAuB,CAACF,CAAD,CAA3C;AACA,SAAOC,aAAa,GAAGF,sBAAhB,GACHC,CAAC,CAACG,aAAF,CAAgBL,eAAhB,CADG,GAEHE,CAAC,CAACd,OAAF,CAAUe,aAAV,CAFJ;AAGH;;AACDnE,OAAO,CAAC6D,wBAAR,GAAmCA,wBAAnC;AACA;;;;;;;AAMA,SAASO,uBAAT,CAAiCF,CAAjC,EAAoC;AAChC,MAAI,CAACI,MAAM,CAACC,QAAP,CAAgBL,CAAhB,CAAD,IAAuBA,CAAC,KAAK,CAA7B,IAAkCA,CAAC,GAAG,CAAtC,IAA2CA,CAAC,GAAG,CAAC,CAApD,EAAuD;AACnD,WAAOF,eAAP;AACH,GAFD,MAGK;AACD,WAAOA,eAAe,GAAG5C,IAAI,CAACqB,KAAL,CAAWrB,IAAI,CAACoD,KAAL,CAAWpD,IAAI,CAACqD,GAAL,CAASP,CAAT,CAAX,CAAX,CAAzB;AACH;AACJ;;AACDlE,OAAO,CAACoE,uBAAR,GAAkCA,uBAAlC;AACA;;;;;;;AAMA,IAAIM,mBAAmB;AAAG;AAAe,UAAUhE,MAAV,EAAkB;AACvDjE,EAAAA,SAAS,CAACiI,mBAAD,EAAsBhE,MAAtB,CAAT;;AACA,WAASgE,mBAAT,CAA6BC,MAA7B,EAAqCC,IAArC,EAA2C;AACvC,QAAID,MAAM,KAAK,KAAK,CAApB,EAAuB;AAAEA,MAAAA,MAAM,GAAG,QAAT;AAAoB;;AAC7C,QAAIhE,KAAK,GAAGD,MAAM,CAACf,IAAP,CAAY,IAAZ,EAAkB;AAC1BwC,MAAAA,UAAU,EAAE,UAAUC,KAAV,EAAiBvB,IAAjB,EAAuB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AACrF,iBAAOlC,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnC,iBAAK4D,WAAL;;AACA,gBAAI,KAAKD,IAAL,CAAUE,UAAV,KAAyB,OAA7B,EAAsC;AAClC,mBAAKC,UAAL,CAAgBlE,IAAhB,EAAsB,QAAtB,EAAgC,KAAKgE,WAArC;AACH;;AACD,mBAAO,CAAC;AAAE;AAAH,aAAP;AACH,WANiB,CAAlB;AAOH,SARoD,CAAhB;AAQhC,OATqB;AAU1B3B,MAAAA,UAAU,EAAE,UAAU3B,KAAV,EAAiBV,IAAjB,EAAuB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AACrF,iBAAOlC,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnC,iBAAK8D,UAAL,CAAgBlE,IAAhB,EAAsB,QAAtB,EAAgCU,KAAK,GAAG,CAAxC;AACA,mBAAO,CAAC;AAAE;AAAH,aAAP;AACH,WAHiB,CAAlB;AAIH,SALoD,CAAhB;AAKhC,OAfqB;AAgB1ByD,MAAAA,UAAU,EAAE,UAAUnE,IAAV,EAAgB;AAAE,eAAOtD,SAAS,CAACoD,KAAD,EAAQ,KAAK,CAAb,EAAgB,KAAK,CAArB,EAAwB,YAAY;AAC9E,iBAAOlC,WAAW,CAAC,IAAD,EAAO,UAAUwC,EAAV,EAAc;AACnC,gBAAI,KAAKgE,WAAL,IAAoB,IAAxB,EAA8B;AAC1B,mBAAKA,WAAL,CAAiBC,KAAjB;AACH;;AACD,gBAAI,KAAKC,SAAL,IAAkB,IAAtB,EAA4B;AACxB,mBAAKA,SAAL,CAAeD,KAAf;AACH;;AACD,mBAAO,CAAC;AAAE;AAAH,aAAP;AACH,WARiB,CAAlB;AASH,SAV6C,CAAhB;AAUzB;AA1BqB,KAAlB,KA2BN,IA3BN;;AA4BAvE,IAAAA,KAAK,CAACgE,MAAN,GAAeA,MAAf;AACAhE,IAAAA,KAAK,CAACiE,IAAN,GAAaA,IAAI,IAAI,IAAR,GAAe,EAAf,GAAoBA,IAAjC;;AACA,QAAIjE,KAAK,CAACiE,IAAN,CAAWE,UAAX,IAAyB,IAA7B,EAAmC;AAC/BnE,MAAAA,KAAK,CAACiE,IAAN,CAAWE,UAAX,GAAwB,OAAxB;AACH;;AACD7E,IAAAA,MAAM,CAACyB,IAAP,CAAY0D,MAAZ,CAAmB,CAAC,OAAD,EAAU,OAAV,EAAmBC,OAAnB,CAA2B1E,KAAK,CAACiE,IAAN,CAAWE,UAAtC,MAAsD,CAAC,CAA1E,EAA6E,YAAY;AAAE,aAAO,4DAC7F,KAAKnE,KAAK,CAACiE,IAAN,CAAWE,UAD6E,CAAP;AACxD,KADnC;AAEAnE,IAAAA,KAAK,CAACkE,WAAN,GAAoB,CAApB;AACA,WAAOlE,KAAP;AACH;;AACD+D,EAAAA,mBAAmB,CAACrH,SAApB,CAA8B0H,UAA9B,GAA2C,UAAUlE,IAAV,EAAgByE,MAAhB,EAAwBrH,IAAxB,EAA8B;AACrE,SAAK,IAAI0F,GAAT,IAAgB9C,IAAhB,EAAsB;AAClB,UAAI8C,GAAG,KAAK,OAAR,IAAmBA,GAAG,KAAK,MAA3B,IAAqCA,GAAG,KAAK,WAAjD,EAA8D;AAC1D;AACH;;AACD,UAAI4B,UAAU,GAAG,MAAjB;;AACA,UAAI5B,GAAG,CAAC6B,UAAJ,CAAeD,UAAf,CAAJ,EAAgC;AAC5B,aAAKE,sBAAL;AACA,YAAIC,UAAU,GAAGJ,MAAM,GAAG3B,GAAG,CAACG,KAAJ,CAAUyB,UAAU,CAAC1F,MAArB,CAA1B;AACA,aAAKsF,SAAL,CAAeQ,MAAf,CAAsBD,UAAtB,EAAkC7E,IAAI,CAAC8C,GAAD,CAAtC,EAA6C1F,IAA7C;AACH,OAJD,MAKK;AACD,aAAK2H,wBAAL;AACA,aAAKX,WAAL,CAAiBU,MAAjB,CAAwB,KAAKL,MAAL,GAAc3B,GAAtC,EAA2C9C,IAAI,CAAC8C,GAAD,CAA/C,EAAsD1F,IAAtD;AACH;AACJ;AACJ,GAhBD;;AAiBAyG,EAAAA,mBAAmB,CAACrH,SAApB,CAA8BuI,wBAA9B,GAAyD,YAAY;AACjE,SAAKX,WAAL,GAAmB5E,aAAa,CAACwF,iBAAd,CAAgC1F,IAAI,CAAC2F,IAAL,CAAU,KAAKnB,MAAf,EAAuB,OAAvB,CAAhC,CAAnB;AACH,GAFD;;AAGAD,EAAAA,mBAAmB,CAACrH,SAApB,CAA8BoI,sBAA9B,GAAuD,YAAY;AAC/D,SAAKN,SAAL,GAAiB9E,aAAa,CAACwF,iBAAd,CAAgC1F,IAAI,CAAC2F,IAAL,CAAU,KAAKnB,MAAf,EAAuB,KAAvB,CAAhC,CAAjB;AACH,GAFD;;AAGA,SAAOD,mBAAP;AACH,CAlEwC,CAkEvCzE,MAAM,CAAC8D,cAlEgC,CAAzC;;AAmEA/D,OAAO,CAAC0E,mBAAR,GAA8BA,mBAA9B;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmDA;;;;AAGA,SAASqB,WAAT,CAAqBpB,MAArB,EAA6BC,IAA7B,EAAmC;AAC/B,MAAID,MAAM,KAAK,KAAK,CAApB,EAAuB;AAAEA,IAAAA,MAAM,GAAG,QAAT;AAAoB;;AAC7C,SAAO,IAAID,mBAAJ,CAAwBC,MAAxB,EAAgCC,IAAhC,CAAP;AACH;;AACD5E,OAAO,CAAC+F,WAAR,GAAsBA,WAAtB","sourcesContent":["\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\nvar path = require(\"path\");\nvar ProgressBar = require(\"progress\");\nvar tensorboard_1 = require(\"./tensorboard\");\n// A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\nexports.progressBarHelper = {\n    ProgressBar: ProgressBar,\n    log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\nvar ProgbarLogger = /** @class */ (function (_super) {\n    __extends(ProgbarLogger, _super);\n    /**\n     * Construtor of LoggingCallback.\n     */\n    function ProgbarLogger() {\n        var _this = _super.call(this, {\n            onTrainBegin: function (logs) { return __awaiter(_this, void 0, void 0, function () {\n                var samples, batchSize, steps;\n                return __generator(this, function (_a) {\n                    samples = this.params.samples;\n                    batchSize = this.params.batchSize;\n                    steps = this.params.steps;\n                    if (samples != null || steps != null) {\n                        this.numTrainBatchesPerEpoch =\n                            samples != null ? Math.ceil(samples / batchSize) : steps;\n                    }\n                    else {\n                        // Undetermined number of batches per epoch, e.g., due to\n                        // `fitDataset()` without `batchesPerEpoch`.\n                        this.numTrainBatchesPerEpoch = 0;\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onEpochBegin: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    exports.progressBarHelper.log(\"Epoch \" + (epoch + 1) + \" / \" + this.params.epochs);\n                    this.currentEpochBegin = tfjs_1.util.now();\n                    this.epochDurationMillis = null;\n                    this.usPerStep = null;\n                    this.batchesInLatestEpoch = 0;\n                    this.terminalWidth = process.stderr.columns;\n                    return [2 /*return*/];\n                });\n            }); },\n            onBatchEnd: function (batch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                var maxMetricsStringLength, tickTokens;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0:\n                            this.batchesInLatestEpoch++;\n                            if (batch === 0) {\n                                this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                                    width: Math.floor(0.5 * this.terminalWidth),\n                                    total: this.numTrainBatchesPerEpoch + 1,\n                                    head: \">\",\n                                    renderThrottle: this.RENDER_THROTTLE_MS\n                                });\n                            }\n                            maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                            tickTokens = {\n                                placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                            };\n                            if (this.numTrainBatchesPerEpoch === 0) {\n                                // Undetermined number of batches per epoch.\n                                this.progressBar.tick(0, tickTokens);\n                            }\n                            else {\n                                this.progressBar.tick(tickTokens);\n                            }\n                            return [4 /*yield*/, tfjs_1.nextFrame()];\n                        case 1:\n                            _a.sent();\n                            if (batch === this.numTrainBatchesPerEpoch - 1) {\n                                this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                                this.usPerStep = this.params.samples != null ?\n                                    this.epochDurationMillis / this.params.samples * 1e3 :\n                                    this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                            }\n                            return [2 /*return*/];\n                    }\n                });\n            }); },\n            onEpochEnd: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                var lossesAndMetricsString;\n                return __generator(this, function (_a) {\n                    switch (_a.label) {\n                        case 0:\n                            if (this.epochDurationMillis == null) {\n                                // In cases where the number of batches per epoch is not determined,\n                                // the calculation of the per-step duration is done at the end of the\n                                // epoch. N.B., this includes the time spent on validation.\n                                this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                                this.usPerStep =\n                                    this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                            }\n                            this.progressBar.tick({ placeholderForLossesAndMetrics: '' });\n                            lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                            exports.progressBarHelper.log(this.epochDurationMillis.toFixed(0) + \"ms \" +\n                                (this.usPerStep.toFixed(0) + \"us/step - \") +\n                                (\"\" + lossesAndMetricsString));\n                            return [4 /*yield*/, tfjs_1.nextFrame()];\n                        case 1:\n                            _a.sent();\n                            return [2 /*return*/];\n                    }\n                });\n            }); },\n        }) || this;\n        _this.RENDER_THROTTLE_MS = 50;\n        return _this;\n    }\n    ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n        var metricsContent = '';\n        var keys = Object.keys(logs).sort();\n        for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n            var key = keys_1[_i];\n            if (this.isFieldRelevant(key)) {\n                var value = logs[key];\n                metricsContent += key + \"=\" + getSuccinctNumberDisplay(value) + \" \";\n            }\n        }\n        if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n            // Cut off metrics strings that are too long to avoid new lines being\n            // constantly created.\n            metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n        }\n        return metricsContent;\n    };\n    ProgbarLogger.prototype.isFieldRelevant = function (key) {\n        return key !== 'batch' && key !== 'size';\n    };\n    return ProgbarLogger;\n}(tfjs_1.CustomCallback));\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\nfunction getSuccinctNumberDisplay(x) {\n    var decimalPlaces = getDisplayDecimalPlaces(x);\n    return decimalPlaces > MAX_NUM_DECIMAL_PLACES ?\n        x.toExponential(BASE_NUM_DIGITS) :\n        x.toFixed(decimalPlaces);\n}\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\nfunction getDisplayDecimalPlaces(x) {\n    if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n        return BASE_NUM_DIGITS;\n    }\n    else {\n        return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n    }\n}\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\nvar TensorBoardCallback = /** @class */ (function (_super) {\n    __extends(TensorBoardCallback, _super);\n    function TensorBoardCallback(logdir, args) {\n        if (logdir === void 0) { logdir = './logs'; }\n        var _this = _super.call(this, {\n            onBatchEnd: function (batch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    this.batchesSeen++;\n                    if (this.args.updateFreq !== 'epoch') {\n                        this.logMetrics(logs, 'batch_', this.batchesSeen);\n                    }\n                    return [2 /*return*/];\n                });\n            }); },\n            onEpochEnd: function (epoch, logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    this.logMetrics(logs, 'epoch_', epoch + 1);\n                    return [2 /*return*/];\n                });\n            }); },\n            onTrainEnd: function (logs) { return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    if (this.trainWriter != null) {\n                        this.trainWriter.flush();\n                    }\n                    if (this.valWriter != null) {\n                        this.valWriter.flush();\n                    }\n                    return [2 /*return*/];\n                });\n            }); }\n        }) || this;\n        _this.logdir = logdir;\n        _this.args = args == null ? {} : args;\n        if (_this.args.updateFreq == null) {\n            _this.args.updateFreq = 'epoch';\n        }\n        tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () { return \"Expected updateFreq to be 'batch' or 'epoch', but got \" +\n            (\"\" + _this.args.updateFreq); });\n        _this.batchesSeen = 0;\n        return _this;\n    }\n    TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n        for (var key in logs) {\n            if (key === 'batch' || key === 'size' || key === 'num_steps') {\n                continue;\n            }\n            var VAL_PREFIX = 'val_';\n            if (key.startsWith(VAL_PREFIX)) {\n                this.ensureValWriterCreated();\n                var scalarName = prefix + key.slice(VAL_PREFIX.length);\n                this.valWriter.scalar(scalarName, logs[key], step);\n            }\n            else {\n                this.ensureTrainWriterCreated();\n                this.trainWriter.scalar(\"\" + prefix + key, logs[key], step);\n            }\n        }\n    };\n    TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n        this.trainWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'train'));\n    };\n    TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n        this.valWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'val'));\n    };\n    return TensorBoardCallback;\n}(tfjs_1.CustomCallback));\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n */\n/**\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\nfunction tensorBoard(logdir, args) {\n    if (logdir === void 0) { logdir = './logs'; }\n    return new TensorBoardCallback(logdir, args);\n}\nexports.tensorBoard = tensorBoard;\n"]},"metadata":{},"sourceType":"script"}