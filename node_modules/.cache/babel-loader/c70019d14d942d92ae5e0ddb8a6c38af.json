{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport { notEqual, serialization, tidy, zerosLike } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Embedding extends Layer {\n  constructor(args) {\n    super(args);\n    this.embeddings = null;\n    this.DEFAULT_EMBEDDINGS_INITIALIZER = 'randomUniform';\n\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      let batchSize = null;\n\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        this.batchInputShape = [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n\n    this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n    this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n    this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    this.maskZero = args.maskZero;\n    this.supportsMasking = args.maskZero;\n    this.inputLength = args.inputLength;\n  }\n\n  build(inputShape) {\n    this.embeddings = this.addWeight('embeddings', [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);\n    this.built = true;\n  } // Override warnOnIncompatibleInputShape because an embedding layer allows\n  // the input to have varying ranks.\n\n\n  warnOnIncompatibleInputShape(inputShape) {}\n\n  computeMask(inputs, mask) {\n    return tidy(() => {\n      if (!this.maskZero) {\n        return null;\n      } else {\n        inputs = getExactlyOneTensor(inputs);\n        return notEqual(inputs, zerosLike(inputs));\n      }\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    if (this.inputLength == null) {\n      return [...inputShape, this.outputDim];\n    } // inputLength can be an array if input is 3D or higher.\n\n\n    const inLens = generic_utils.toList(this.inputLength);\n\n    if (inLens.length !== inputShape.length - 1) {\n      throw new ValueError(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received \") + \"input shape has shape \".concat(inputShape));\n    } else {\n      let i = 0;\n\n      for (let k = 0; k < inLens.length; ++k) {\n        const s1 = inLens[k];\n        const s2 = inputShape[k + 1];\n\n        if (s1 != null && s2 != null && s1 !== s2) {\n          throw new ValueError(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received \") + \"input shape has shape \".concat(inputShape));\n        } else if (s1 == null) {\n          inLens[i] = s2;\n        }\n\n        i++;\n      }\n    }\n\n    return [inputShape[0], ...inLens, this.outputDim];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs); // Embedding layer accepts only a single input.\n\n      let input = getExactlyOneTensor(inputs);\n\n      if (input.dtype !== 'int32') {\n        input = K.cast(input, 'int32');\n      }\n\n      const output = K.gather(this.embeddings.read(), input.as1D());\n      return output.reshape(getExactlyOneShape(this.computeOutputShape(input.shape)));\n    });\n  }\n\n  getConfig() {\n    const config = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nEmbedding.className = 'Embedding';\nserialization.registerClass(Embedding);","map":null,"metadata":{},"sourceType":"module"}