{"ast":null,"code":"import _slicedToArray from \"/home/victor/COVID-19-Coding-Fest/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport { CLASSES } from './classes';\nconst BASE_PATH = 'https://storage.googleapis.com/tfjs-models/savedmodel/';\nexport { version } from './version';\nexport async function load(config = {}) {\n  if (tf == null) {\n    throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" + \"also include @tensorflow/tfjs on the page before using this model.\");\n  }\n\n  const base = config.base || 'lite_mobilenet_v2';\n  const modelUrl = config.modelUrl;\n\n  if (['mobilenet_v1', 'mobilenet_v2', 'lite_mobilenet_v2'].indexOf(base) === -1) {\n    throw new Error(\"ObjectDetection constructed with invalid base model \" + \"\".concat(base, \". Valid names are 'mobilenet_v1',\") + \" 'mobilenet_v2' and 'lite_mobilenet_v2'.\");\n  }\n\n  const objectDetection = new ObjectDetection(base, modelUrl);\n  await objectDetection.load();\n  return objectDetection;\n}\nexport class ObjectDetection {\n  constructor(base, modelUrl) {\n    this.modelPath = modelUrl || \"\".concat(BASE_PATH).concat(this.getPrefix(base), \"/model.json\");\n  }\n\n  getPrefix(base) {\n    return base === 'lite_mobilenet_v2' ? \"ssd\".concat(base) : \"ssd_\".concat(base);\n  }\n\n  async load() {\n    this.model = await tfconv.loadGraphModel(this.modelPath);\n    const zeroTensor = tf.zeros([1, 300, 300, 3], 'int32'); // Warmup the model.\n\n    const result = await this.model.executeAsync(zeroTensor);\n    await Promise.all(result.map(t => t.data()));\n    result.map(t => t.dispose());\n    zeroTensor.dispose();\n  }\n  /**\n   * Infers through the model.\n   *\n   * @param img The image to classify. Can be a tensor or a DOM element image,\n   * video, or canvas.\n   * @param maxNumBoxes The maximum number of bounding boxes of detected\n   * objects. There can be multiple objects of the same class, but at different\n   * locations. Defaults to 20.\n   * @param minScore The minimum score of the returned bounding boxes\n   * of detected objects. Value between 0 and 1. Defaults to 0.5.\n   */\n\n\n  async infer(img, maxNumBoxes, minScore) {\n    const batched = tf.tidy(() => {\n      if (!(img instanceof tf.Tensor)) {\n        img = tf.browser.fromPixels(img);\n      } // Reshape to a single-element batch so we can pass it to executeAsync.\n\n\n      return img.expandDims(0);\n    });\n    const height = batched.shape[1];\n    const width = batched.shape[2]; // model returns two tensors:\n    // 1. box classification score with shape of [1, 1917, 90]\n    // 2. box location with shape of [1, 1917, 1, 4]\n    // where 1917 is the number of box detectors, 90 is the number of classes.\n    // and 4 is the four coordinates of the box.\n\n    const result = await this.model.executeAsync(batched);\n    const scores = result[0].dataSync();\n    const boxes = result[1].dataSync(); // clean the webgl tensors\n\n    batched.dispose();\n    tf.dispose(result);\n\n    const _this$calculateMaxSco = this.calculateMaxScores(scores, result[0].shape[1], result[0].shape[2]),\n          _this$calculateMaxSco2 = _slicedToArray(_this$calculateMaxSco, 2),\n          maxScores = _this$calculateMaxSco2[0],\n          classes = _this$calculateMaxSco2[1];\n\n    const prevBackend = tf.getBackend(); // run post process in cpu\n\n    tf.setBackend('cpu');\n    const indexTensor = tf.tidy(() => {\n      const boxes2 = tf.tensor2d(boxes, [result[1].shape[1], result[1].shape[3]]);\n      return tf.image.nonMaxSuppression(boxes2, maxScores, maxNumBoxes, minScore, minScore);\n    });\n    const indexes = indexTensor.dataSync();\n    indexTensor.dispose(); // restore previous backend\n\n    tf.setBackend(prevBackend);\n    return this.buildDetectedObjects(width, height, boxes, maxScores, indexes, classes);\n  }\n\n  buildDetectedObjects(width, height, boxes, scores, indexes, classes) {\n    const count = indexes.length;\n    const objects = [];\n\n    for (let i = 0; i < count; i++) {\n      const bbox = [];\n\n      for (let j = 0; j < 4; j++) {\n        bbox[j] = boxes[indexes[i] * 4 + j];\n      }\n\n      const minY = bbox[0] * height;\n      const minX = bbox[1] * width;\n      const maxY = bbox[2] * height;\n      const maxX = bbox[3] * width;\n      bbox[0] = minX;\n      bbox[1] = minY;\n      bbox[2] = maxX - minX;\n      bbox[3] = maxY - minY;\n      objects.push({\n        bbox: bbox,\n        class: CLASSES[classes[indexes[i]] + 1].displayName,\n        score: scores[indexes[i]]\n      });\n    }\n\n    return objects;\n  }\n\n  calculateMaxScores(scores, numBoxes, numClasses) {\n    const maxes = [];\n    const classes = [];\n\n    for (let i = 0; i < numBoxes; i++) {\n      let max = Number.MIN_VALUE;\n      let index = -1;\n\n      for (let j = 0; j < numClasses; j++) {\n        if (scores[i * numClasses + j] > max) {\n          max = scores[i * numClasses + j];\n          index = j;\n        }\n      }\n\n      maxes[i] = max;\n      classes[i] = index;\n    }\n\n    return [maxes, classes];\n  }\n  /**\n   * Detect objects for an image returning a list of bounding boxes with\n   * assocated class and score.\n   *\n   * @param img The image to detect objects from. Can be a tensor or a DOM\n   *     element image, video, or canvas.\n   * @param maxNumBoxes The maximum number of bounding boxes of detected\n   * objects. There can be multiple objects of the same class, but at different\n   * locations. Defaults to 20.\n   * @param minScore The minimum score of the returned bounding boxes\n   * of detected objects. Value between 0 and 1. Defaults to 0.5.\n   */\n\n\n  async detect(img, maxNumBoxes = 20, minScore = 0.5) {\n    return this.infer(img, maxNumBoxes, minScore);\n  }\n  /**\n   * Dispose the tensors allocated by the model. You should call this when you\n   * are done with the model.\n   */\n\n\n  dispose() {\n    if (this.model != null) {\n      this.model.dispose();\n    }\n  }\n\n}","map":null,"metadata":{},"sourceType":"module"}