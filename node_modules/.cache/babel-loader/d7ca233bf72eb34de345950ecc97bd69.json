{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original source: keras/callbacks.py */\nimport { add, div, keep, mul, nextFrame, tidy, util } from '@tensorflow/tfjs-core';\nimport { ValueError } from './errors';\nimport { resolveScalarsInLogs } from './logs';\nimport * as generic_utils from './utils/generic_utils';\n/** Verbosity logging level when fitting a model. */\n\nexport var ModelLoggingVerbosity;\n\n(function (ModelLoggingVerbosity) {\n  ModelLoggingVerbosity[ModelLoggingVerbosity[\"SILENT\"] = 0] = \"SILENT\";\n  ModelLoggingVerbosity[ModelLoggingVerbosity[\"VERBOSE\"] = 1] = \"VERBOSE\";\n})(ModelLoggingVerbosity || (ModelLoggingVerbosity = {}));\n/** How often to yield to the main thread when training (in ms). */\n\n\nexport const DEFAULT_YIELD_EVERY_MS = 125;\n/**\n * Abstract base class used to build new callbacks.\n *\n * The `logs` dictionary that callback methods take as argument will contain\n * keys for quantities relevant to the current batch or epoch.\n *\n * Currently, the `.fit()` method of the `Sequential` model class\n * will include the following quantities in the `logs` that\n * it passes to its callbacks:\n *\n * onEpochEnd: Logs include `acc` and `loss`, and optionally include `valLoss`\n *   (if validation is enabled in `fit`), and `valAcc` (if validation and\n *   accuracy monitoring are enabled).\n * onBatchBegin: Logs include `size`, the number of samples in the current\n *   batch.\n * onBatchEnd: Logs include `loss`, and optionally `acc` (if accuracy monitoring\n *   is enabled).\n */\n\nexport class BaseCallback {\n  constructor() {\n    // TODO(michaelterry): This type is a best guess.\n    this.validationData = null;\n  }\n\n  setParams(params) {\n    this.params = params;\n  }\n\n  async onEpochBegin(epoch, logs) {}\n\n  async onEpochEnd(epoch, logs) {}\n\n  async onBatchBegin(batch, logs) {}\n\n  async onBatchEnd(batch, logs) {}\n\n  async onTrainBegin(logs) {}\n\n  async onTrainEnd(logs) {} // LayersModel needs to call Callback.setModel(), but cannot actually depend\n  // on Callback because that creates a cyclic dependency.  Providing this no-op\n  // method on BaseCallback breaks the cycle: this way LayersModel can depend on\n  // BaseCallback but not on Callback.  The argument is typed as `Container`\n  // (the superclass of LayersModel) to avoid recapitulating the cycle. Callback\n  // overrides this method and enforces that the argument is really a\n  // LayersModel.\n\n\n  setModel(model) {// Do nothing. Use Callback instead of BaseCallback to track the model.\n  }\n\n}\n/**\n * Container abstracting a list of callbacks.\n */\n\nexport class CallbackList {\n  // TODO(cais): When the need arises, uncomment the following lines and\n  // implement the queue for time values.\n  // private deltaTBatch: number;\n  // private deltaTsBatchBegin: Array<number>;\n  // private deltaTsBatchEnd: Array<number>;\n\n  /**\n   * Constructor of CallbackList.\n   * @param callbacks Array of `Callback` instances.\n   * @param queueLength Queue length for keeping running statistics over\n   *   callback execution time.\n   */\n  constructor(callbacks, queueLength = 10) {\n    // TODO(cais): Make use of queueLength when implementing the queue for time\n    // values.\n    if (callbacks == null) {\n      callbacks = [];\n    }\n\n    this.callbacks = callbacks;\n    this.queueLength = queueLength;\n  }\n\n  append(callback) {\n    this.callbacks.push(callback);\n  }\n\n  setParams(params) {\n    for (const callback of this.callbacks) {\n      callback.setParams(params);\n    }\n  }\n\n  setModel(model) {\n    for (const callback of this.callbacks) {\n      callback.setModel(model);\n    }\n  }\n  /**\n   * Called at the start of an epoch.\n   * @param epoch Index of epoch.\n   * @param logs Dictionary of logs.\n   */\n\n\n  async onEpochBegin(epoch, logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    for (const callback of this.callbacks) {\n      await callback.onEpochBegin(epoch, logs);\n    }\n  }\n  /**\n   * Called at the end of an epoch.\n   * @param epoch Index of epoch.\n   * @param logs Dictionary of logs.\n   */\n\n\n  async onEpochEnd(epoch, logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    for (const callback of this.callbacks) {\n      await callback.onEpochEnd(epoch, logs);\n    }\n  }\n  /**\n   * Called  right before processing a batch.\n   * @param batch Index of batch within the current epoch.\n   * @param logs Dictionary of logs.\n   */\n\n\n  async onBatchBegin(batch, logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    for (const callback of this.callbacks) {\n      await callback.onBatchBegin(batch, logs);\n    }\n  }\n  /**\n   * Called at the end of a batch.\n   * @param batch Index of batch within the current epoch.\n   * @param logs Dictionary of logs.\n   */\n\n\n  async onBatchEnd(batch, logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    for (const callback of this.callbacks) {\n      await callback.onBatchEnd(batch, logs);\n    }\n  }\n  /**\n   * Called at the beginning of training.\n   * @param logs Dictionary of logs.\n   */\n\n\n  async onTrainBegin(logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    for (const callback of this.callbacks) {\n      await callback.onTrainBegin(logs);\n    }\n  }\n  /**\n   * Called at the end of training.\n   * @param logs Dictionary of logs.\n   */\n\n\n  async onTrainEnd(logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    for (const callback of this.callbacks) {\n      await callback.onTrainEnd(logs);\n    }\n  }\n\n}\n/**\n * Callback that accumulates epoch averages of metrics.\n *\n * This callback is automatically applied to every LayersModel.\n */\n\nexport class BaseLogger extends BaseCallback {\n  constructor() {\n    super();\n  }\n\n  async onEpochBegin(epoch) {\n    this.seen = 0;\n    this.totals = {};\n  }\n\n  async onBatchEnd(batch, logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    const batchSize = logs['size'] == null ? 0 : logs['size'];\n    this.seen += batchSize;\n\n    for (const key in logs) {\n      const value = logs[key];\n\n      if (typeof value === 'number') {\n        if (!this.totals.hasOwnProperty(key)) {\n          this.totals[key] = 0;\n        }\n\n        this.totals[key] = this.totals[key] + value * batchSize;\n      } else {\n        let oldTotalsToDispose;\n\n        if (key in this.totals) {\n          oldTotalsToDispose = this.totals[key];\n        } else {\n          this.totals[key] = 0;\n        }\n\n        const total = tidy(() => add(this.totals[key], mul(value, batchSize)));\n        this.totals[key] = total;\n\n        if (oldTotalsToDispose != null) {\n          oldTotalsToDispose.dispose();\n        }\n      }\n    }\n  }\n\n  async onEpochEnd(epoch, logs) {\n    if (logs != null) {\n      for (const key of this.params['metrics']) {\n        if (this.totals[key] == null) {\n          continue;\n        }\n\n        if (typeof this.totals[key] === 'number') {\n          logs[key] = this.totals[key] / this.seen;\n        } else {\n          tidy(() => {\n            const log = mul(div(1, this.seen), this.totals[key]);\n            logs[key] = log;\n            this.totals[key].dispose();\n            keep(logs[key]);\n          });\n        }\n      }\n    }\n  }\n\n}\n/**\n * Callback that records events into a `History` object. This callback is\n * automatically applied to every TF.js Layers model. The `History` object\n * gets returned by the `fit` method of models.\n */\n\nexport class History extends BaseCallback {\n  async onTrainBegin(logs) {\n    this.epoch = [];\n    this.history = {};\n  }\n\n  async onEpochEnd(epoch, logs) {\n    if (logs == null) {\n      logs = {};\n    }\n\n    this.epoch.push(epoch);\n\n    for (const key in logs) {\n      if (this.history[key] == null) {\n        this.history[key] = [];\n      }\n\n      this.history[key].push(logs[key]);\n    }\n  }\n  /**\n   * Await the values of all losses and metrics.\n   */\n\n\n  async syncData() {\n    const promises = [];\n    const keys = [];\n    const indices = [];\n\n    for (const key in this.history) {\n      const valueArray = this.history[key];\n\n      for (let i = 0; i < valueArray.length; ++i) {\n        if (typeof valueArray[i] !== 'number') {\n          const valueScalar = valueArray[i];\n          promises.push(valueScalar.data());\n          keys.push(key);\n          indices.push(i);\n        }\n      }\n    }\n\n    const values = await Promise.all(promises);\n\n    for (let n = 0; n < values.length; ++n) {\n      const tensorToDispose = this.history[keys[n]][indices[n]];\n      tensorToDispose.dispose();\n      this.history[keys[n]][indices[n]] = values[n][0];\n    }\n  }\n\n}\n/**\n * Custom callback for training.\n */\n\nexport class CustomCallback extends BaseCallback {\n  constructor(args, yieldEvery) {\n    super();\n    this.currentEpoch = 0;\n    this.yieldEvery = yieldEvery || 'auto';\n\n    if (this.yieldEvery === 'auto') {\n      this.yieldEvery = DEFAULT_YIELD_EVERY_MS;\n    }\n\n    if (this.yieldEvery === 'never' && args.onYield != null) {\n      throw new Error('yieldEvery is `never` but you provided an `onYield` callback. ' + 'Either change `yieldEvery` or remove the callback');\n    }\n\n    if (util.isNumber(this.yieldEvery)) {\n      // Decorate `maybeWait` so it will be called at most once every\n      // `yieldEvery` ms.\n      this.maybeWait = generic_utils.debounce(this.maybeWait.bind(this), this.yieldEvery);\n    }\n\n    this.trainBegin = args.onTrainBegin;\n    this.trainEnd = args.onTrainEnd;\n    this.epochBegin = args.onEpochBegin;\n    this.epochEnd = args.onEpochEnd;\n    this.batchBegin = args.onBatchBegin;\n    this.batchEnd = args.onBatchEnd;\n    this.yield = args.onYield;\n  }\n\n  async maybeWait(epoch, batch, logs) {\n    const ps = [];\n\n    if (this.yield != null) {\n      await resolveScalarsInLogs(logs);\n      ps.push(this.yield(epoch, batch, logs));\n    }\n\n    ps.push(nextFrame());\n    await Promise.all(ps);\n  }\n\n  async onEpochBegin(epoch, logs) {\n    this.currentEpoch = epoch;\n\n    if (this.epochBegin != null) {\n      await resolveScalarsInLogs(logs);\n      await this.epochBegin(epoch, logs);\n    }\n  }\n\n  async onEpochEnd(epoch, logs) {\n    const ps = [];\n\n    if (this.epochEnd != null) {\n      await resolveScalarsInLogs(logs);\n      ps.push(this.epochEnd(epoch, logs));\n    }\n\n    if (this.yieldEvery === 'epoch') {\n      ps.push(nextFrame());\n    }\n\n    await Promise.all(ps);\n  }\n\n  async onBatchBegin(batch, logs) {\n    if (this.batchBegin != null) {\n      await resolveScalarsInLogs(logs);\n      await this.batchBegin(batch, logs);\n    }\n  }\n\n  async onBatchEnd(batch, logs) {\n    const ps = [];\n\n    if (this.batchEnd != null) {\n      await resolveScalarsInLogs(logs);\n      ps.push(this.batchEnd(batch, logs));\n    }\n\n    if (this.yieldEvery === 'batch') {\n      ps.push(nextFrame());\n    } else if (util.isNumber(this.yieldEvery)) {\n      ps.push(this.maybeWait(this.currentEpoch, batch, logs));\n    }\n\n    await Promise.all(ps);\n  }\n\n  async onTrainBegin(logs) {\n    if (this.trainBegin != null) {\n      await resolveScalarsInLogs(logs);\n      await this.trainBegin(logs);\n    }\n  }\n\n  async onTrainEnd(logs) {\n    if (this.trainEnd != null) {\n      await resolveScalarsInLogs(logs);\n      await this.trainEnd(logs);\n    }\n  }\n\n}\n/**\n * Standardize callbacks or configurations of them to an Array of callbacks.\n */\n\nexport function standardizeCallbacks(callbacks, yieldEvery) {\n  if (callbacks == null) {\n    callbacks = {};\n  }\n\n  if (callbacks instanceof BaseCallback) {\n    return [callbacks];\n  }\n\n  if (Array.isArray(callbacks) && callbacks[0] instanceof BaseCallback) {\n    return callbacks;\n  } // Convert custom callback configs to custom callback objects.\n\n\n  const callbackConfigs = generic_utils.toList(callbacks);\n  return callbackConfigs.map(callbackConfig => new CustomCallback(callbackConfig, yieldEvery));\n}\n/**\n * A global registry for callback constructors to be used during\n * LayersModel.fit().\n */\n\nexport class CallbackConstructorRegistry {\n  /**\n   * Blocks public access to constructor.\n   */\n  constructor() {}\n  /**\n   * Register a tf.LayersModel.fit() callback constructor.\n   *\n   * The registered callback constructor will be used to instantiate\n   * callbacks for every tf.LayersModel.fit() call afterwards.\n   *\n   * @param verbosityLevel Level of verbosity at which the `callbackConstructor`\n   *   is to be reigstered.\n   * @param callbackConstructor A no-arg constructor for `tf.Callback`.\n   * @throws Error, if the same callbackConstructor has been registered before,\n   *   either at the same or a different `verbosityLevel`.\n   */\n\n\n  static registerCallbackConstructor(verbosityLevel, callbackConstructor) {\n    util.assert(verbosityLevel >= 0 && Number.isInteger(verbosityLevel), () => \"Verbosity level is expected to be an integer >= 0, \" + \"but got \".concat(verbosityLevel));\n    CallbackConstructorRegistry.checkForDuplicate(callbackConstructor);\n\n    if (CallbackConstructorRegistry.constructors[verbosityLevel] == null) {\n      CallbackConstructorRegistry.constructors[verbosityLevel] = [];\n    }\n\n    CallbackConstructorRegistry.constructors[verbosityLevel].push(callbackConstructor);\n  }\n\n  static checkForDuplicate(callbackConstructor) {\n    for (const levelName in CallbackConstructorRegistry.constructors) {\n      const constructors = CallbackConstructorRegistry.constructors[+levelName];\n      constructors.forEach(ctor => {\n        if (ctor === callbackConstructor) {\n          throw new ValueError('Duplicate callback constructor.');\n        }\n      });\n    }\n  }\n  /**\n   * Clear all registered callback constructors.\n   */\n\n\n  static clear() {\n    CallbackConstructorRegistry.constructors = {};\n  }\n  /**\n   * Create callbacks using the registered callback constructors.\n   *\n   * Given `verbosityLevel`, all constructors registered at that level or above\n   * will be called and the instantiated callbacks will be used.\n   *\n   * @param verbosityLevel: Level of verbosity.\n   */\n\n\n  static createCallbacks(verbosityLevel) {\n    const constructors = [];\n\n    for (const levelName in CallbackConstructorRegistry.constructors) {\n      const level = +levelName;\n\n      if (verbosityLevel >= level) {\n        constructors.push(...CallbackConstructorRegistry.constructors[level]);\n      }\n    }\n\n    return constructors.map(ctor => new ctor());\n  }\n\n}\nCallbackConstructorRegistry.constructors = {};\nexport function configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics) {\n  const history = new History();\n  const actualCallbacks = [new BaseLogger(), ...CallbackConstructorRegistry.createCallbacks(verbose)];\n\n  if (callbacks != null) {\n    actualCallbacks.push(...callbacks);\n  }\n\n  actualCallbacks.push(history);\n  const callbackList = new CallbackList(actualCallbacks); // TODO(cais): Figure out when this LayersModel instance can have a\n  // dynamically\n  //   set property called 'callback_model' as in PyKeras.\n\n  callbackList.setParams({\n    epochs,\n    initialEpoch,\n    samples: numTrainSamples,\n    steps: stepsPerEpoch,\n    batchSize,\n    verbose,\n    doValidation,\n    metrics: callbackMetrics\n  });\n  return {\n    callbackList,\n    history\n  };\n}","map":null,"metadata":{},"sourceType":"module"}